{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.nn import GCNConv, MessagePassing\n",
    "import random\n",
    "from matplotlib.pyplot import rc_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data\n",
    "adata = scanpy.read_h5ad('adata_head_S_v1.0.h5ad')\n",
    "\n",
    "sampled_indices_obs = adata.obs.sample(frac=0.1, random_state=42).index\n",
    "sampled_indices_var = adata.var.sample(frac=0.1, random_state=42).index\n",
    "sampled_data = adata[sampled_indices_obs, sampled_indices_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the gene-gene correlation matrix\n",
    "gene_gene_interactions = np.load('gg_interactions.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes before filtering: 1184\n",
      "Number of genes after filtering: 1184\n"
     ]
    }
   ],
   "source": [
    "# Converting & filtering\n",
    "# Load the mapping file of protein IDs to preferred names\n",
    "mapping_file = '7227.protein.info.v11.5.txt'  # Path to your mapping file\n",
    "protein_mapping = {}\n",
    "\n",
    "# Read the mapping file and populate the protein_mapping dictionary\n",
    "with open(mapping_file, 'r') as file:\n",
    "    next(file)  # Skip the header line if present\n",
    "    for line in file:\n",
    "        protein_id, preferred_name, _, _ = line.strip().split('\\t')\n",
    "        protein_mapping[preferred_name] = protein_id\n",
    "\n",
    "# Remove genes not in the interaction matrix from sampled_data\n",
    "sampled_data = sampled_data[:, [protein_mapping.get(gene, None) is not None for gene in sampled_data.var_names]]\n",
    "\n",
    "# Update the var_names in sampled_data with protein IDs\n",
    "sampled_data.var_names = [protein_mapping.get(gene, None) for gene in sampled_data.var_names]\n",
    "\n",
    "# Print the number of genes before and after filtering\n",
    "print(\"Number of genes before filtering:\", sampled_data.X.shape[1])\n",
    "print(\"Number of genes after filtering:\", sampled_data.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of genes present in sampled_data.var_names\n",
    "selected_genes = set(sampled_data.var_names)\n",
    "\n",
    "# Find the indices of selected genes in the gene_gene_interactions matrix\n",
    "gene_indices = [i for i, gene in enumerate(gene_gene_interactions[0]) if gene in selected_genes]\n",
    "\n",
    "# Filter gene_gene_interactions matrix\n",
    "filtered_interactions = gene_gene_interactions[gene_indices][:, gene_indices]\n",
    "filtered_interactions = filtered_interactions.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining and training the model\n",
    "gene_expression = sampled_data.X.toarray()  # Gene expression data, shape: (num_cells, num_genes)\n",
    "gene_names = sampled_data.var_names # List of gene names in the same order as gene_expression\n",
    "\n",
    "adjacency_matrix = filtered_interactions # Matrix is not weighted - should weight it\n",
    "\n",
    "# Convert elements of adjacency_matrix to a numeric type\n",
    "adjacency_matrix = np.array(adjacency_matrix, dtype=np.float32)\n",
    "\n",
    "adjacency_tensor = torch.tensor(adjacency_matrix, dtype=torch.float)\n",
    "gene_expression_tensor = torch.tensor(gene_expression, dtype=torch.float)\n",
    "\n",
    "edge_index = torch.nonzero(adjacency_tensor != 0, as_tuple=False).t()\n",
    "\n",
    "# Set y to be either sex or age\n",
    "sex_matrix = np.array([0 if sex == \"female\" else 1 for sex in np.array(sampled_data.obs.sex)])\n",
    "age_matrix = np.array([0 if age == \"5\" else 1 if age == \"30\" else 2 if age == \"50\" else 3 for age in np.array(sampled_data.obs.age)])\n",
    "data = Data(x=gene_expression_tensor, edge_index=edge_index, edge_attr=adjacency_tensor, y=age_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 26168\n",
      "Validation set size: 26168\n",
      "Test set size: 29438\n",
      "x tensor([[ 0.2342,  0.1543, -0.5926, -0.0831],\n",
      "        [-0.0151, -0.5212, -0.2462, -0.2578],\n",
      "        [ 0.2730,  0.1734, -0.4794, -0.0868],\n",
      "        ...,\n",
      "        [ 1.5978, -0.7168, -1.0910, -0.2555],\n",
      "        [ 1.0733,  0.0377, -0.6206,  0.1673],\n",
      "        [ 0.0748,  0.1413, -0.8264, -0.2385]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.1278, -1.2076, -1.9546, -1.4451],\n",
      "        [-1.1572, -1.6633, -1.3883, -1.3999],\n",
      "        [-1.1230, -1.2227, -1.8755, -1.4828],\n",
      "        ...,\n",
      "        [-0.2803, -2.5949, -2.9691, -2.1336],\n",
      "        [-0.6642, -1.6998, -2.3580, -1.5702],\n",
      "        [-1.1650, -1.0985, -2.0662, -1.4783]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 1.4649\n",
      "x tensor([[-4.2908, -5.2834,  6.0560, -1.1786],\n",
      "        [-3.0244, -4.9407,  4.6302, -1.7838],\n",
      "        [-3.7691, -4.5338,  5.0301, -0.8479],\n",
      "        ...,\n",
      "        [-4.5939, -5.4558,  6.0048, -1.1786],\n",
      "        [-6.2755, -6.9979,  8.5295, -0.9822],\n",
      "        [-3.6699, -5.0876,  7.0449, -3.1543]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0348e+01, -1.1340e+01, -7.6491e-04, -7.2353e+00],\n",
      "        [-7.6568e+00, -9.5731e+00, -2.1797e-03, -6.4162e+00],\n",
      "        [-8.8023e+00, -9.5669e+00, -3.0167e-03, -5.8811e+00],\n",
      "        ...,\n",
      "        [-1.0599e+01, -1.1461e+01, -7.9433e-04, -7.1842e+00],\n",
      "        [-1.4805e+01, -1.5527e+01, -7.4622e-05, -9.5118e+00],\n",
      "        [-1.0715e+01, -1.2133e+01, -6.4729e-05, -1.0199e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 8.4076\n",
      "x tensor([[-0.8872, -1.1913,  1.0610,  0.5509],\n",
      "        [ 0.2357, -1.4761,  0.7411, -0.2328],\n",
      "        [-0.9081, -1.0068,  0.7964,  0.6964],\n",
      "        ...,\n",
      "        [-1.7752, -1.5980,  1.5126,  0.4519],\n",
      "        [-1.6384, -1.9240,  1.6853,  0.8599],\n",
      "        [ 0.1142, -1.7796,  1.5510, -1.0719]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-2.5624, -2.8665, -0.6142, -1.1243],\n",
      "        [-1.2424, -2.9542, -0.7371, -1.7110],\n",
      "        [-2.5161, -2.6147, -0.8116, -0.9116],\n",
      "        ...,\n",
      "        [-3.6442, -3.4670, -0.3563, -1.4171],\n",
      "        [-3.7299, -4.0155, -0.4062, -1.2317],\n",
      "        [-1.7340, -3.6278, -0.2972, -2.9201]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 2.0177\n",
      "x tensor([[ 1.1590,  0.1411, -0.8557, -0.0910],\n",
      "        [ 2.4842, -0.2624, -1.0534, -0.6239],\n",
      "        [ 0.8477,  0.1281, -0.7183,  0.1462],\n",
      "        ...,\n",
      "        [ 0.8861,  0.7577, -1.0983,  0.1010],\n",
      "        [ 1.5461, -0.0548, -1.3347,  0.3609],\n",
      "        [ 2.9478, -0.6032, -1.3036, -1.6153]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-0.5773, -1.5951, -2.5920, -1.8273],\n",
      "        [-0.1292, -2.8758, -3.6668, -3.2372],\n",
      "        [-0.7847, -1.5043, -2.3507, -1.4862],\n",
      "        ...,\n",
      "        [-0.9055, -1.0338, -2.8898, -1.6906],\n",
      "        [-0.4469, -2.0479, -3.3277, -1.6321],\n",
      "        [-0.0520, -3.6030, -4.3034, -4.6151]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 1.3723\n",
      "x tensor([[ 0.8405,  1.0461, -1.0569, -0.6236],\n",
      "        [ 2.5270,  0.8085, -1.4352, -1.4362],\n",
      "        [ 0.5779,  0.8818, -0.8590, -0.3625],\n",
      "        ...,\n",
      "        [ 0.3540,  1.9733, -1.4254, -0.3430],\n",
      "        [ 0.8249,  1.2744, -1.6683, -0.2057],\n",
      "        [ 2.6715,  0.8021, -1.8280, -2.2288]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-0.9592, -0.7536, -2.8566, -2.4232],\n",
      "        [-0.1967, -1.9151, -4.1588, -4.1599],\n",
      "        [-1.0930, -0.7891, -2.5299, -2.0334],\n",
      "        ...,\n",
      "        [-1.9045, -0.2852, -3.6840, -2.6016],\n",
      "        [-1.1010, -0.6514, -3.5941, -2.1315],\n",
      "        [-0.1594, -2.0288, -4.6588, -5.0597]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 1.5392\n",
      "x tensor([[ 0.8278,  0.5739, -0.6829, -0.3447],\n",
      "        [ 2.5239,  0.3993, -1.1468, -1.3445],\n",
      "        [ 0.5920,  0.4721, -0.5331, -0.1364],\n",
      "        ...,\n",
      "        [ 0.1891,  1.4562, -1.0394, -0.1203],\n",
      "        [ 0.6956,  0.8071, -1.2249,  0.1924],\n",
      "        [ 2.5586,  0.3267, -1.4110, -1.7182]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-0.8355, -1.0895, -2.3463, -2.0081],\n",
      "        [-0.1534, -2.2781, -3.8242, -4.0218],\n",
      "        [-0.9911, -1.1111, -2.1163, -1.7195],\n",
      "        ...,\n",
      "        [-1.7187, -0.4516, -2.9472, -2.0281],\n",
      "        [-1.0540, -0.9425, -2.9745, -1.5572],\n",
      "        [-0.1311, -2.3630, -4.1007, -4.4079]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 1.3170\n",
      "x tensor([[ 7.2761e-01,  1.3705e-01, -3.8938e-01, -5.9430e-02],\n",
      "        [ 2.3686e+00, -1.3773e-01, -8.1399e-01, -1.0555e+00],\n",
      "        [ 5.5188e-01,  1.0930e-01, -2.8313e-01,  5.7547e-02],\n",
      "        ...,\n",
      "        [ 2.1882e-03,  9.4970e-01, -6.5378e-01,  1.7420e-01],\n",
      "        [ 5.1197e-01,  3.5179e-01, -7.3823e-01,  6.1666e-01],\n",
      "        [ 2.2829e+00, -2.4076e-01, -9.0713e-01, -9.9960e-01]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-0.8486, -1.4392, -1.9656, -1.6357],\n",
      "        [-0.1446, -2.6509, -3.3272, -3.5687],\n",
      "        [-0.9881, -1.4307, -1.8231, -1.4825],\n",
      "        ...,\n",
      "        [-1.6650, -0.7175, -2.3210, -1.4930],\n",
      "        [-1.1783, -1.3385, -2.4285, -1.0736],\n",
      "        [-0.1474, -2.6711, -3.3375, -3.4300]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 1.1902\n",
      "x tensor([[ 0.5807, -0.0376, -0.1993,  0.1054],\n",
      "        [ 2.0637, -0.3404, -0.6082, -0.8247],\n",
      "        [ 0.4229, -0.0307, -0.1388,  0.1800],\n",
      "        ...,\n",
      "        [-0.2217,  0.7263, -0.3907,  0.2749],\n",
      "        [ 0.2220,  0.2437, -0.3682,  0.7425],\n",
      "        [ 1.9301, -0.4891, -0.6197, -0.6929]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-0.9628, -1.5811, -1.7428, -1.4381],\n",
      "        [-0.1949, -2.5989, -2.8668, -3.0832],\n",
      "        [-1.0953, -1.5488, -1.6569, -1.3382],\n",
      "        ...,\n",
      "        [-1.8031, -0.8550, -1.9720, -1.3065],\n",
      "        [-1.4490, -1.4273, -2.0393, -0.9286],\n",
      "        [-0.2148, -2.6341, -2.7647, -2.8379]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 1.1490\n",
      "x tensor([[ 0.4358, -0.0196, -0.0527,  0.0764],\n",
      "        [ 1.8185, -0.3188, -0.4789, -0.9009],\n",
      "        [ 0.2732, -0.0386, -0.0560,  0.1478],\n",
      "        ...,\n",
      "        [-0.4305,  0.7154, -0.1466,  0.2097],\n",
      "        [-0.0695,  0.3275, -0.0852,  0.6779],\n",
      "        [ 1.7451, -0.4871, -0.4289, -0.9810]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0804, -1.5358, -1.5689, -1.4398],\n",
      "        [-0.2503, -2.3876, -2.5477, -2.9696],\n",
      "        [-1.2041, -1.5159, -1.5333, -1.3295],\n",
      "        ...,\n",
      "        [-1.9975, -0.8516, -1.7135, -1.3573],\n",
      "        [-1.7198, -1.3228, -1.7354, -0.9724],\n",
      "        [-0.2519, -2.4841, -2.4259, -2.9780]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 1.1162\n",
      "x tensor([[ 0.3361,  0.0823,  0.0402, -0.2024],\n",
      "        [ 1.7196, -0.1529, -0.4141, -1.2621],\n",
      "        [ 0.1826,  0.0450,  0.0231, -0.0668],\n",
      "        ...,\n",
      "        [-0.6197,  0.8228,  0.0838,  0.0375],\n",
      "        [-0.3015,  0.4825,  0.1126,  0.3372],\n",
      "        [ 1.7199, -0.2939, -0.3720, -1.7944]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.1325, -1.3863, -1.4284, -1.6710],\n",
      "        [-0.2798, -2.1523, -2.4135, -3.2614],\n",
      "        [-1.2537, -1.3913, -1.4132, -1.5031],\n",
      "        ...,\n",
      "        [-2.2172, -0.7747, -1.5137, -1.5599],\n",
      "        [-1.8867, -1.1026, -1.4725, -1.2480],\n",
      "        [-0.2521, -2.2659, -2.3440, -3.7663]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 1.0815\n",
      "x tensor([[ 0.3331,  0.1393,  0.0323, -0.6313],\n",
      "        [ 1.9090, -0.1076, -0.5133, -1.8526],\n",
      "        [ 0.1710,  0.0869,  0.0371, -0.3600],\n",
      "        ...,\n",
      "        [-0.8392,  0.9488,  0.2124, -0.2668],\n",
      "        [-0.4301,  0.6322,  0.1470, -0.2409],\n",
      "        [ 2.0230, -0.1972, -0.4767, -2.7933]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0802, -1.2740, -1.3810, -2.0446],\n",
      "        [-0.2192, -2.2358, -2.6415, -3.9808],\n",
      "        [-1.2185, -1.3026, -1.3524, -1.7495],\n",
      "        ...,\n",
      "        [-2.4520, -0.6641, -1.4004, -1.8797],\n",
      "        [-1.9289, -0.8666, -1.3518, -1.7397],\n",
      "        [-0.1813, -2.4016, -2.6810, -4.9976]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 1.0640\n",
      "x tensor([[ 0.5789,  0.0037,  0.0352, -0.7156],\n",
      "        [ 2.3883, -0.2821, -0.6419, -2.0673],\n",
      "        [ 0.3543, -0.0383,  0.0600, -0.3636],\n",
      "        ...,\n",
      "        [-1.0084,  0.9115,  0.2970, -0.2382],\n",
      "        [-0.2425,  0.5425,  0.2459, -0.2807],\n",
      "        [ 2.6773, -0.4953, -0.5874, -3.1949]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-0.8826, -1.4578, -1.4263, -2.1771],\n",
      "        [-0.1215, -2.7919, -3.1517, -4.5771],\n",
      "        [-1.0675, -1.4601, -1.3618, -1.7854],\n",
      "        ...,\n",
      "        [-2.6151, -0.6953, -1.3098, -1.8450],\n",
      "        [-1.7552, -0.9702, -1.2668, -1.7935],\n",
      "        [-0.0797, -3.2522, -3.3443, -5.9518]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 1.0407\n",
      "x tensor([[ 0.5119, -0.1380,  0.0484, -0.4552],\n",
      "        [ 2.5352, -0.4091, -0.7708, -1.9731],\n",
      "        [ 0.2830, -0.1516,  0.0775, -0.1412],\n",
      "        ...,\n",
      "        [-1.2883,  0.8291,  0.3460, -0.0355],\n",
      "        [-0.3820,  0.3593,  0.2970,  0.0690],\n",
      "        [ 2.9229, -0.7697, -0.7076, -3.0646]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-0.9287, -1.5787, -1.3923, -1.8959],\n",
      "        [-0.0956, -3.0399, -3.4016, -4.6039],\n",
      "        [-1.1366, -1.5712, -1.3421, -1.5608],\n",
      "        ...,\n",
      "        [-2.8868, -0.7694, -1.2525, -1.6340],\n",
      "        [-1.8932, -1.1519, -1.2142, -1.4422],\n",
      "        [-0.0525, -3.7451, -3.6830, -6.0400]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.9937\n",
      "x tensor([[ 0.2145, -0.1608,  0.0762, -0.1980],\n",
      "        [ 2.4234, -0.3570, -0.9003, -1.8557],\n",
      "        [ 0.0323, -0.1855,  0.1048,  0.0992],\n",
      "        ...,\n",
      "        [-1.7288,  0.7676,  0.4108,  0.2295],\n",
      "        [-0.9371,  0.3194,  0.3389,  0.4674],\n",
      "        [ 2.7800, -0.6579, -0.8465, -2.9764]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.1693, -1.5446, -1.3077, -1.5819],\n",
      "        [-0.1061, -2.8865, -3.4298, -4.3852],\n",
      "        [-1.3734, -1.5911, -1.3009, -1.3065],\n",
      "        ...,\n",
      "        [-3.3577, -0.8613, -1.2181, -1.3993],\n",
      "        [-2.4989, -1.2424, -1.2229, -1.0944],\n",
      "        [-0.0601, -3.4980, -3.6866, -5.8165]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.9575\n",
      "x tensor([[ 0.0429, -0.0327,  0.0269, -0.2288],\n",
      "        [ 2.4841, -0.2177, -1.1065, -2.0101],\n",
      "        [-0.1166, -0.1214,  0.0812,  0.1482],\n",
      "        ...,\n",
      "        [-2.1860,  0.7073,  0.5122,  0.3720],\n",
      "        [-1.4119,  0.3180,  0.3402,  0.6546],\n",
      "        [ 2.8651, -0.4241, -1.1215, -3.4026]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.3011, -1.3767, -1.3171, -1.5728],\n",
      "        [-0.1006, -2.8024, -3.6912, -4.5948],\n",
      "        [-1.5079, -1.5127, -1.3100, -1.2431],\n",
      "        ...,\n",
      "        [-3.8462, -0.9529, -1.1480, -1.2882],\n",
      "        [-3.0108, -1.2810, -1.2587, -0.9443],\n",
      "        [-0.0561, -3.3453, -4.0427, -6.3238]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.9360\n",
      "x tensor([[ 0.2323, -0.0216, -0.1169, -0.5357],\n",
      "        [ 2.9390, -0.1744, -1.4212, -2.4596],\n",
      "        [ 0.0191, -0.1301, -0.0150, -0.0281],\n",
      "        ...,\n",
      "        [-2.3535,  0.6365,  0.6028,  0.2751],\n",
      "        [-1.2971,  0.2995,  0.2437,  0.4492],\n",
      "        [ 3.5254, -0.3828, -1.5474, -4.2593]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0801, -1.3340, -1.4293, -1.8481],\n",
      "        [-0.0599, -3.1733, -4.4201, -5.4586],\n",
      "        [-1.3302, -1.4794, -1.3643, -1.3774],\n",
      "        ...,\n",
      "        [-3.9883, -0.9984, -1.0321, -1.3598],\n",
      "        [-2.7934, -1.1969, -1.2527, -1.0472],\n",
      "        [-0.0264, -3.9346, -5.0993, -7.8112]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.9006\n",
      "x tensor([[ 0.4147, -0.3036, -0.1302, -0.7574],\n",
      "        [ 3.4116, -0.4296, -1.6002, -2.8627],\n",
      "        [ 0.1535, -0.3780, -0.0149, -0.1410],\n",
      "        ...,\n",
      "        [-2.5392,  0.2530,  0.8159,  0.2906],\n",
      "        [-1.2123, -0.1333,  0.3318,  0.3959],\n",
      "        [ 4.2289, -0.7677, -1.7756, -4.9360]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-0.8659, -1.5842, -1.4108, -2.0380],\n",
      "        [-0.0296, -3.8707, -5.0414, -6.3038],\n",
      "        [-1.1561, -1.6876, -1.3246, -1.4506],\n",
      "        ...,\n",
      "        [-4.1417, -1.3495, -0.7865, -1.3119],\n",
      "        [-2.6115, -1.5325, -1.0674, -1.0033],\n",
      "        [-0.0093, -5.0058, -6.0137, -9.1741]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.8831\n",
      "x tensor([[ 0.1207, -0.2409,  0.0122, -0.9434],\n",
      "        [ 3.2531, -0.1959, -1.5788, -3.0679],\n",
      "        [-0.0842, -0.3370,  0.1106, -0.2231],\n",
      "        ...,\n",
      "        [-3.0700,  0.1672,  1.1538,  0.2590],\n",
      "        [-1.7916, -0.1449,  0.5550,  0.3088],\n",
      "        [ 4.0593, -0.4342, -1.7504, -5.3729]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0780, -1.4396, -1.1865, -2.1421],\n",
      "        [-0.0407, -3.4897, -4.8725, -6.3617],\n",
      "        [-1.3512, -1.6040, -1.1564, -1.4901],\n",
      "        ...,\n",
      "        [-4.8095, -1.5722, -0.5857, -1.4804],\n",
      "        [-3.2112, -1.5645, -0.8646, -1.1109],\n",
      "        [-0.0142, -4.5077, -5.8239, -9.4463]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.8614\n",
      "x tensor([[-0.0429, -0.0236, -0.0546, -0.9479],\n",
      "        [ 3.1412,  0.2043, -1.7888, -3.0953],\n",
      "        [-0.2281, -0.1775,  0.0691, -0.1847],\n",
      "        ...,\n",
      "        [-3.5632,  0.1149,  1.3210,  0.3558],\n",
      "        [-2.2110,  0.0263,  0.5052,  0.4490],\n",
      "        [ 3.9826,  0.0744, -2.0491, -5.5219]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.2274, -1.2081, -1.2391, -2.1324],\n",
      "        [-0.0603, -2.9973, -4.9904, -6.2969],\n",
      "        [-1.4912, -1.4406, -1.1940, -1.4478],\n",
      "        ...,\n",
      "        [-5.4076, -1.7295, -0.5234, -1.4887],\n",
      "        [-3.6835, -1.4462, -0.9673, -1.0236],\n",
      "        [-0.0223, -3.9305, -6.0540, -9.5268]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.8501\n",
      "x tensor([[ 2.4729e-01, -1.2894e-01, -3.4219e-01, -6.9412e-01],\n",
      "        [ 3.5100e+00,  1.1192e-01, -2.2274e+00, -2.8546e+00],\n",
      "        [-2.9039e-03, -2.7069e-01, -1.4906e-01,  4.2711e-02],\n",
      "        ...,\n",
      "        [-3.6885e+00, -2.5065e-01,  1.2976e+00,  6.8030e-01],\n",
      "        [-2.0100e+00, -1.5517e-01,  1.7862e-01,  9.4714e-01],\n",
      "        [ 4.6440e+00, -1.3002e-01, -2.6835e+00, -5.2781e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.6742e-01, -1.3436e+00, -1.5569e+00, -1.9088e+00],\n",
      "        [-3.7664e-02, -3.4357e+00, -5.7750e+00, -6.4022e+00],\n",
      "        [-1.3018e+00, -1.5695e+00, -1.4479e+00, -1.2561e+00],\n",
      "        ...,\n",
      "        [-5.5508e+00, -2.1129e+00, -5.6466e-01, -1.1820e+00],\n",
      "        [-3.5711e+00, -1.7163e+00, -1.3825e+00, -6.1398e-01],\n",
      "        [-9.1109e-03, -4.7831e+00, -7.3366e+00, -9.9313e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.8367\n",
      "x tensor([[ 0.3721, -0.1100, -0.4807, -0.9121],\n",
      "        [ 3.7064,  0.1411, -2.4567, -3.1286],\n",
      "        [ 0.0888, -0.2626, -0.2513, -0.1196],\n",
      "        ...,\n",
      "        [-3.8818, -0.3715,  1.4154,  0.6524],\n",
      "        [-1.9853, -0.1723,  0.0238,  0.8528],\n",
      "        [ 5.0387, -0.1987, -3.0566, -5.6190]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.4184e-01, -1.3239e+00, -1.6946e+00, -2.1260e+00],\n",
      "        [-3.0986e-02, -3.5962e+00, -6.1940e+00, -6.8660e+00],\n",
      "        [-1.1716e+00, -1.5231e+00, -1.5117e+00, -1.3800e+00],\n",
      "        ...,\n",
      "        [-5.7911e+00, -2.2808e+00, -4.9393e-01, -1.2569e+00],\n",
      "        [-3.4553e+00, -1.6423e+00, -1.4462e+00, -6.1724e-01],\n",
      "        [-5.6269e-03, -5.2430e+00, -8.1010e+00, -1.0663e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.8275\n",
      "x tensor([[ 0.0421, -0.0783, -0.2799, -1.1586],\n",
      "        [ 3.3616,  0.2233, -2.2811, -3.3930],\n",
      "        [-0.1856, -0.2415, -0.0826, -0.3161],\n",
      "        ...,\n",
      "        [-4.3461, -0.3628,  1.7500,  0.5350],\n",
      "        [-2.5492, -0.1827,  0.3090,  0.6664],\n",
      "        [ 4.6618, -0.1816, -2.8822, -5.8959]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0689e+00, -1.1893e+00, -1.3909e+00, -2.2696e+00],\n",
      "        [-4.6947e-02, -3.1852e+00, -5.6897e+00, -6.8016e+00],\n",
      "        [-1.3691e+00, -1.4250e+00, -1.2661e+00, -1.4996e+00],\n",
      "        ...,\n",
      "        [-6.4467e+00, -2.4634e+00, -3.5056e-01, -1.5655e+00],\n",
      "        [-3.9892e+00, -1.6227e+00, -1.1310e+00, -7.7351e-01],\n",
      "        [-8.3996e-03, -4.8519e+00, -7.5524e+00, -1.0566e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.8143\n",
      "x tensor([[-0.0515, -0.2273, -0.2253, -1.0887],\n",
      "        [ 3.2511,  0.0988, -2.2541, -3.3249],\n",
      "        [-0.2655, -0.3613, -0.0312, -0.2668],\n",
      "        ...,\n",
      "        [-4.6193, -0.5175,  1.9268,  0.6402],\n",
      "        [-2.7824, -0.3970,  0.3811,  0.8913],\n",
      "        [ 4.6119, -0.4178, -2.9279, -5.7064]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.1098e+00, -1.2856e+00, -1.2836e+00, -2.1469e+00],\n",
      "        [-4.7086e-02, -3.1994e+00, -5.5522e+00, -6.6231e+00],\n",
      "        [-1.4282e+00, -1.5240e+00, -1.1940e+00, -1.4295e+00],\n",
      "        ...,\n",
      "        [-6.8569e+00, -2.7551e+00, -3.1073e-01, -1.5973e+00],\n",
      "        [-4.3163e+00, -1.9309e+00, -1.1529e+00, -6.4262e-01],\n",
      "        [-7.0798e-03, -5.0369e+00, -7.5469e+00, -1.0325e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.8086\n",
      "x tensor([[ 0.2218, -0.1212, -0.5438, -1.0353],\n",
      "        [ 3.5074,  0.2570, -2.6028, -3.2759],\n",
      "        [-0.0425, -0.2715, -0.2840, -0.2362],\n",
      "        ...,\n",
      "        [-4.5762, -0.4941,  1.7916,  0.7252],\n",
      "        [-2.5022, -0.2390, -0.0687,  1.0749],\n",
      "        [ 5.0892, -0.3169, -3.5079, -5.5412]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.9983e-01, -1.2428e+00, -1.6654e+00, -2.1569e+00],\n",
      "        [-4.1249e-02, -3.2916e+00, -6.1514e+00, -6.8246e+00],\n",
      "        [-1.2252e+00, -1.4541e+00, -1.4667e+00, -1.4188e+00],\n",
      "        ...,\n",
      "        [-6.7378e+00, -2.6556e+00, -3.6997e-01, -1.4363e+00],\n",
      "        [-4.0567e+00, -1.7935e+00, -1.6232e+00, -4.7958e-01],\n",
      "        [-4.6873e-03, -5.4107e+00, -8.6018e+00, -1.0635e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.7945\n",
      "x tensor([[ 0.1997, -0.0945, -0.6184, -0.8964],\n",
      "        [ 3.4421,  0.3473, -2.6702, -3.1427],\n",
      "        [-0.0596, -0.2459, -0.3405, -0.1331],\n",
      "        ...,\n",
      "        [-4.6816, -0.4412,  1.7835,  0.8001],\n",
      "        [-2.5812, -0.1754, -0.2119,  1.3190],\n",
      "        [ 5.1247, -0.3320, -3.7095, -5.2588]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.2452e-01, -1.2186e+00, -1.7426e+00, -2.0206e+00],\n",
      "        [-4.7724e-02, -3.1425e+00, -6.1600e+00, -6.6325e+00],\n",
      "        [-1.2568e+00, -1.4431e+00, -1.5377e+00, -1.3304e+00],\n",
      "        ...,\n",
      "        [-6.8597e+00, -2.6192e+00, -3.9455e-01, -1.3779e+00],\n",
      "        [-4.2793e+00, -1.8735e+00, -1.9100e+00, -3.7910e-01],\n",
      "        [-4.4346e-03, -5.4611e+00, -8.8386e+00, -1.0388e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.7890\n",
      "x tensor([[-0.0552, -0.2042, -0.3758, -0.8876],\n",
      "        [ 3.1495,  0.2893, -2.3822, -3.1771],\n",
      "        [-0.2714, -0.3298, -0.1428, -0.1316],\n",
      "        ...,\n",
      "        [-4.9415, -0.4444,  2.0149,  0.6961],\n",
      "        [-2.9300, -0.2811,  0.0558,  1.4090],\n",
      "        [ 4.8368, -0.5606, -3.4147, -5.1968]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.1060e+00, -1.2550e+00, -1.4266e+00, -1.9385e+00],\n",
      "        [-6.1095e-02, -2.9214e+00, -5.5928e+00, -6.3878e+00],\n",
      "        [-1.4424e+00, -1.5007e+00, -1.3137e+00, -1.3026e+00],\n",
      "        ...,\n",
      "        [-7.2594e+00, -2.7622e+00, -3.0301e-01, -1.6218e+00],\n",
      "        [-4.7147e+00, -2.0658e+00, -1.7288e+00, -3.7567e-01],\n",
      "        [-4.8211e-03, -5.4023e+00, -8.2563e+00, -1.0038e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.7773\n",
      "x tensor([[-0.0447, -0.1786, -0.3129, -1.1018],\n",
      "        [ 3.1457,  0.3555, -2.2592, -3.4681],\n",
      "        [-0.2611, -0.3021, -0.0941, -0.3127],\n",
      "        ...,\n",
      "        [-4.9431, -0.3201,  2.0938,  0.4175],\n",
      "        [-2.8984, -0.1673,  0.0722,  1.1703],\n",
      "        [ 4.8903, -0.6358, -3.3454, -5.4599]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0942e+00, -1.2281e+00, -1.3624e+00, -2.1514e+00],\n",
      "        [-6.5084e-02, -2.8552e+00, -5.4700e+00, -6.6788e+00],\n",
      "        [-1.4089e+00, -1.4499e+00, -1.2419e+00, -1.4604e+00],\n",
      "        ...,\n",
      "        [-7.2817e+00, -2.6587e+00, -2.4483e-01, -1.9211e+00],\n",
      "        [-4.5469e+00, -1.8158e+00, -1.5762e+00, -4.7813e-01],\n",
      "        [-4.2692e-03, -5.5304e+00, -8.2400e+00, -1.0354e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.7719\n",
      "x tensor([[ 0.1591, -0.2352, -0.4525, -0.9983],\n",
      "        [ 3.2870,  0.3198, -2.3380, -3.4025],\n",
      "        [-0.0931, -0.3362, -0.2111, -0.2371],\n",
      "        ...,\n",
      "        [-4.8044, -0.2664,  1.9688,  0.4469],\n",
      "        [-2.6677, -0.1432, -0.1963,  1.3533],\n",
      "        [ 5.1884, -0.8424, -3.5479, -5.2669]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.2860e-01, -1.3229e+00, -1.5401e+00, -2.0860e+00],\n",
      "        [-5.4772e-02, -3.0219e+00, -5.6797e+00, -6.7442e+00],\n",
      "        [-1.2638e+00, -1.5069e+00, -1.3818e+00, -1.4078e+00],\n",
      "        ...,\n",
      "        [-7.0557e+00, -2.5176e+00, -2.8249e-01, -1.8043e+00],\n",
      "        [-4.3954e+00, -1.8710e+00, -1.9241e+00, -3.7443e-01],\n",
      "        [-2.5898e-03, -6.0334e+00, -8.7389e+00, -1.0458e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.7617\n",
      "x tensor([[ 0.0828, -0.2331, -0.4784, -0.7234],\n",
      "        [ 3.0652,  0.3903, -2.3021, -3.1589],\n",
      "        [-0.1565, -0.3227, -0.2374, -0.0190],\n",
      "        ...,\n",
      "        [-4.9111, -0.1754,  1.9169,  0.6318],\n",
      "        [-2.8349, -0.0493, -0.3284,  1.7257],\n",
      "        [ 5.0334, -0.9240, -3.5626, -4.8179]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0102e+00, -1.3261e+00, -1.5714e+00, -1.8165e+00],\n",
      "        [-7.2838e-02, -2.7478e+00, -5.4402e+00, -6.2970e+00],\n",
      "        [-1.3652e+00, -1.5314e+00, -1.4461e+00, -1.2277e+00],\n",
      "        ...,\n",
      "        [-7.1652e+00, -2.4296e+00, -3.3727e-01, -1.6223e+00],\n",
      "        [-4.8292e+00, -2.0436e+00, -2.3227e+00, -2.6862e-01],\n",
      "        [-2.8203e-03, -5.9602e+00, -8.5988e+00, -9.8541e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.7550\n",
      "x tensor([[-0.0664, -0.1645, -0.3611, -0.7692],\n",
      "        [ 2.7788,  0.4971, -2.0997, -3.2601],\n",
      "        [-0.2724, -0.2612, -0.1484, -0.0627],\n",
      "        ...,\n",
      "        [-5.0986, -0.0205,  1.9976,  0.5323],\n",
      "        [-3.0634,  0.1484, -0.2852,  1.7009],\n",
      "        [ 4.7183, -0.9121, -3.3456, -4.8259]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.1463e+00, -1.2444e+00, -1.4410e+00, -1.8491e+00],\n",
      "        [-1.0625e-01, -2.3880e+00, -4.9848e+00, -6.1452e+00],\n",
      "        [-1.4762e+00, -1.4650e+00, -1.3523e+00, -1.2666e+00],\n",
      "        ...,\n",
      "        [-7.4071e+00, -2.3291e+00, -3.1098e-01, -1.7762e+00],\n",
      "        [-5.0699e+00, -1.8581e+00, -2.2918e+00, -3.0563e-01],\n",
      "        [-3.9657e-03, -5.6343e+00, -8.0679e+00, -9.5481e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.7469\n",
      "x tensor([[ 0.0366, -0.3421, -0.2399, -0.9142],\n",
      "        [ 2.8079,  0.2685, -1.8833, -3.5033],\n",
      "        [-0.1836, -0.3977, -0.0570, -0.1964],\n",
      "        ...,\n",
      "        [-5.0700, -0.0356,  2.0758,  0.3545],\n",
      "        [-2.9500,  0.0222, -0.2178,  1.5878],\n",
      "        [ 4.8322, -1.3048, -3.1105, -5.0197]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0401e+00, -1.4188e+00, -1.3167e+00, -1.9909e+00],\n",
      "        [-8.6089e-02, -2.6255e+00, -4.7772e+00, -6.3972e+00],\n",
      "        [-1.3685e+00, -1.5826e+00, -1.2420e+00, -1.3813e+00],\n",
      "        ...,\n",
      "        [-7.4087e+00, -2.3743e+00, -2.6290e-01, -1.9841e+00],\n",
      "        [-4.8628e+00, -1.8906e+00, -2.1306e+00, -3.2500e-01],\n",
      "        [-2.5660e-03, -6.1396e+00, -7.9453e+00, -9.8545e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.7402\n",
      "x tensor([[ 0.1271, -0.2841, -0.3081, -0.9440],\n",
      "        [ 2.7795,  0.3276, -1.8699, -3.5949],\n",
      "        [-0.1042, -0.3477, -0.1164, -0.2290],\n",
      "        ...,\n",
      "        [-5.0471,  0.1260,  1.9823,  0.3213],\n",
      "        [-2.8884,  0.1988, -0.4132,  1.6011],\n",
      "        [ 4.8522, -1.3166, -3.1575, -5.0092]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.7558e-01, -1.3867e+00, -1.4107e+00, -2.0466e+00],\n",
      "        [-9.2949e-02, -2.5448e+00, -4.7423e+00, -6.4674e+00],\n",
      "        [-1.2959e+00, -1.5394e+00, -1.3082e+00, -1.4207e+00],\n",
      "        ...,\n",
      "        [-7.3273e+00, -2.1542e+00, -2.9793e-01, -1.9590e+00],\n",
      "        [-4.8193e+00, -1.7320e+00, -2.3440e+00, -3.2980e-01],\n",
      "        [-2.4749e-03, -6.1713e+00, -8.0122e+00, -9.8639e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.7333\n",
      "x tensor([[ 0.0137, -0.2977, -0.3254, -0.6741],\n",
      "        [ 2.5446,  0.3501, -1.8268, -3.3898],\n",
      "        [-0.1949, -0.3561, -0.1310, -0.0123],\n",
      "        ...,\n",
      "        [-5.1897,  0.2085,  1.9073,  0.5423],\n",
      "        [-3.0804,  0.2605, -0.5424,  1.9563],\n",
      "        [ 4.5599, -1.3893, -3.1505, -4.5610]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0810e+00, -1.3923e+00, -1.4201e+00, -1.7688e+00],\n",
      "        [-1.1929e-01, -2.3138e+00, -4.4907e+00, -6.0537e+00],\n",
      "        [-1.4152e+00, -1.5764e+00, -1.3513e+00, -1.2326e+00],\n",
      "        ...,\n",
      "        [-7.4610e+00, -2.0628e+00, -3.6403e-01, -1.7290e+00],\n",
      "        [-5.2774e+00, -1.9365e+00, -2.7394e+00, -2.4071e-01],\n",
      "        [-3.1605e-03, -5.9523e+00, -7.7136e+00, -9.1241e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.7276\n",
      "x tensor([[ 6.1846e-02, -4.0598e-01, -2.7179e-01, -6.6429e-01],\n",
      "        [ 2.5454e+00,  2.3223e-01, -1.6959e+00, -3.4868e+00],\n",
      "        [-1.6395e-01, -4.4637e-01, -8.7818e-02, -1.2738e-03],\n",
      "        ...,\n",
      "        [-5.1564e+00,  2.1712e-01,  1.9088e+00,  5.1573e-01],\n",
      "        [-3.0047e+00,  1.6769e-01, -5.4962e-01,  2.0118e+00],\n",
      "        [ 4.5943e+00, -1.6219e+00, -3.0352e+00, -4.5357e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0390e+00, -1.5069e+00, -1.3727e+00, -1.7652e+00],\n",
      "        [-1.0951e-01, -2.4227e+00, -4.3508e+00, -6.1417e+00],\n",
      "        [-1.3887e+00, -1.6711e+00, -1.3126e+00, -1.2260e+00],\n",
      "        ...,\n",
      "        [-7.4252e+00, -2.0517e+00, -3.6003e-01, -1.7531e+00],\n",
      "        [-5.2331e+00, -2.0608e+00, -2.7781e+00, -2.1672e-01],\n",
      "        [-2.5877e-03, -6.2188e+00, -7.6321e+00, -9.1326e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.7204\n",
      "x tensor([[ 0.1408, -0.3227, -0.2536, -0.9192],\n",
      "        [ 2.6376,  0.2942, -1.5911, -3.8691],\n",
      "        [-0.0990, -0.3933, -0.0719, -0.1979],\n",
      "        ...,\n",
      "        [-5.0468,  0.3624,  1.8966,  0.2387],\n",
      "        [-2.8350,  0.2934, -0.5862,  1.7460],\n",
      "        [ 4.7409, -1.5934, -2.9592, -4.9100]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.7438e-01, -1.4379e+00, -1.3689e+00, -2.0344e+00],\n",
      "        [-1.0622e-01, -2.4496e+00, -4.3349e+00, -6.6130e+00],\n",
      "        [-1.3025e+00, -1.5968e+00, -1.2754e+00, -1.4013e+00],\n",
      "        ...,\n",
      "        [-7.2850e+00, -1.8758e+00, -3.4154e-01, -1.9995e+00],\n",
      "        [-4.8747e+00, -1.7462e+00, -2.6258e+00, -2.9363e-01],\n",
      "        [-2.2889e-03, -6.3365e+00, -7.7024e+00, -9.6532e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.7158\n",
      "x tensor([[ 0.0759, -0.4282, -0.2004, -0.7622],\n",
      "        [ 2.5665,  0.1565, -1.4675, -3.8227],\n",
      "        [-0.1605, -0.4788, -0.0259, -0.0716],\n",
      "        ...,\n",
      "        [-5.0782,  0.3097,  1.9136,  0.3368],\n",
      "        [-2.8786,  0.1512, -0.5631,  1.9515],\n",
      "        [ 4.6392, -1.8225, -2.8502, -4.6650]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0279e+00, -1.5320e+00, -1.3042e+00, -1.8660e+00],\n",
      "        [-1.0364e-01, -2.5136e+00, -4.1376e+00, -6.4928e+00],\n",
      "        [-1.3774e+00, -1.6956e+00, -1.2428e+00, -1.2884e+00],\n",
      "        ...,\n",
      "        [-7.3345e+00, -1.9466e+00, -3.4263e-01, -1.9195e+00],\n",
      "        [-5.0565e+00, -2.0268e+00, -2.7411e+00, -2.2644e-01],\n",
      "        [-2.2096e-03, -6.4640e+00, -7.4917e+00, -9.3064e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.7081\n",
      "x tensor([[ 0.0214, -0.3372, -0.2890, -0.6011],\n",
      "        [ 2.4857,  0.2381, -1.4969, -3.7528],\n",
      "        [-0.2089, -0.4038, -0.0938,  0.0537],\n",
      "        ...,\n",
      "        [-5.1168,  0.4140,  1.8140,  0.4593],\n",
      "        [-2.9527,  0.2597, -0.7223,  2.1607],\n",
      "        [ 4.5103, -1.7673, -2.9478, -4.3759]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0880e+00, -1.4466e+00, -1.3985e+00, -1.7105e+00],\n",
      "        [-1.1888e-01, -2.3665e+00, -4.1015e+00, -6.3573e+00],\n",
      "        [-1.4458e+00, -1.6407e+00, -1.3307e+00, -1.1832e+00],\n",
      "        ...,\n",
      "        [-7.3400e+00, -1.8092e+00, -4.0918e-01, -1.7639e+00],\n",
      "        [-5.3052e+00, -2.0928e+00, -3.0748e+00, -1.9177e-01],\n",
      "        [-2.5897e-03, -6.2801e+00, -7.4607e+00, -8.8888e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.7029\n",
      "x tensor([[ 1.2403e-01, -3.6663e-01, -3.2724e-01, -6.5867e-01],\n",
      "        [ 2.6383e+00,  1.1574e-01, -1.4705e+00, -3.9347e+00],\n",
      "        [-1.2787e-01, -4.2644e-01, -1.2302e-01, -4.6504e-03],\n",
      "        ...,\n",
      "        [-5.0152e+00,  4.0217e-01,  1.7757e+00,  3.8160e-01],\n",
      "        [-2.8093e+00,  1.8510e-01, -7.8828e-01,  2.1440e+00],\n",
      "        [ 4.6899e+00, -1.9414e+00, -2.9616e+00, -4.4263e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.9555e-01, -1.4862e+00, -1.4468e+00, -1.7783e+00],\n",
      "        [-9.3564e-02, -2.6161e+00, -4.2024e+00, -6.6665e+00],\n",
      "        [-1.3553e+00, -1.6539e+00, -1.3504e+00, -1.2321e+00],\n",
      "        ...,\n",
      "        [-7.1979e+00, -1.7806e+00, -4.0706e-01, -1.8012e+00],\n",
      "        [-5.1368e+00, -2.1423e+00, -3.1157e+00, -1.8345e-01],\n",
      "        [-1.9018e-03, -6.6332e+00, -7.6534e+00, -9.1181e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6958\n",
      "x tensor([[ 0.1107, -0.4222, -0.2455, -0.7717],\n",
      "        [ 2.6808, -0.0069, -1.3375, -4.2055],\n",
      "        [-0.1358, -0.4719, -0.0541, -0.1041],\n",
      "        ...,\n",
      "        [-5.0440,  0.3592,  1.8516,  0.2428],\n",
      "        [-2.8447,  0.0642, -0.6863,  2.0929],\n",
      "        [ 4.6893, -2.1333, -2.8097, -4.5494]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.9361e-01, -1.5266e+00, -1.3498e+00, -1.8760e+00],\n",
      "        [-8.3465e-02, -2.7711e+00, -4.1018e+00, -6.9697e+00],\n",
      "        [-1.3433e+00, -1.6795e+00, -1.2616e+00, -1.3117e+00],\n",
      "        ...,\n",
      "        [-7.2504e+00, -1.8473e+00, -3.5484e-01, -1.9636e+00],\n",
      "        [-5.1205e+00, -2.2117e+00, -2.9621e+00, -1.8296e-01],\n",
      "        [-1.7381e-03, -6.8244e+00, -7.5008e+00, -9.2405e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6902\n",
      "x tensor([[ 0.0161, -0.3609, -0.2437, -0.7385],\n",
      "        [ 2.5096,  0.1331, -1.3015, -4.2565],\n",
      "        [-0.2121, -0.4200, -0.0480, -0.0793],\n",
      "        ...,\n",
      "        [-5.1805,  0.4165,  1.8560,  0.2539],\n",
      "        [-3.0529,  0.1062, -0.6946,  2.2213],\n",
      "        [ 4.4873, -2.0963, -2.7983, -4.4285]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0741e+00, -1.4511e+00, -1.3339e+00, -1.8287e+00],\n",
      "        [-1.0988e-01, -2.4864e+00, -3.9210e+00, -6.8761e+00],\n",
      "        [-1.4189e+00, -1.6268e+00, -1.2548e+00, -1.2861e+00],\n",
      "        ...,\n",
      "        [-7.4007e+00, -1.8037e+00, -3.6424e-01, -1.9663e+00],\n",
      "        [-5.4396e+00, -2.2805e+00, -3.0814e+00, -1.6543e-01],\n",
      "        [-2.2000e-03, -6.5858e+00, -7.2877e+00, -8.9180e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6838\n",
      "x tensor([[ 0.1267, -0.4770, -0.3313, -0.5954],\n",
      "        [ 2.6093,  0.0121, -1.3585, -4.2183],\n",
      "        [-0.1323, -0.5049, -0.1129,  0.0257],\n",
      "        ...,\n",
      "        [-5.1218,  0.3143,  1.7742,  0.3690],\n",
      "        [-2.9883, -0.0893, -0.8063,  2.4787],\n",
      "        [ 4.6392, -2.3368, -2.9303, -4.1830]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.8024e-01, -1.5839e+00, -1.4382e+00, -1.7024e+00],\n",
      "        [-9.0274e-02, -2.6875e+00, -4.0581e+00, -6.9179e+00],\n",
      "        [-1.3557e+00, -1.7284e+00, -1.3363e+00, -1.1978e+00],\n",
      "        ...,\n",
      "        [-7.2871e+00, -1.8510e+00, -3.9110e-01, -1.7962e+00],\n",
      "        [-5.5789e+00, -2.6799e+00, -3.3969e+00, -1.1186e-01],\n",
      "        [-1.5962e-03, -6.9775e+00, -7.5711e+00, -8.8238e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6780\n",
      "x tensor([[ 0.1833, -0.3484, -0.3884, -0.7612],\n",
      "        [ 2.6903,  0.1522, -1.3942, -4.5122],\n",
      "        [-0.0901, -0.4027, -0.1545, -0.1003],\n",
      "        ...,\n",
      "        [-5.0870,  0.4185,  1.7491,  0.1961],\n",
      "        [-2.9614,  0.0191, -0.8761,  2.3825],\n",
      "        [ 4.7533, -2.2110, -3.0225, -4.4154]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.3254e-01, -1.4643e+00, -1.5043e+00, -1.8771e+00],\n",
      "        [-9.2203e-02, -2.6304e+00, -4.1767e+00, -7.2947e+00],\n",
      "        [-1.2972e+00, -1.6098e+00, -1.3616e+00, -1.3074e+00],\n",
      "        ...,\n",
      "        [-7.2262e+00, -1.7206e+00, -3.9001e-01, -1.9431e+00],\n",
      "        [-5.4726e+00, -2.4921e+00, -3.3873e+00, -1.2867e-01],\n",
      "        [-1.4681e-03, -6.9658e+00, -7.7772e+00, -9.1702e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6720\n",
      "x tensor([[ 0.1183, -0.5319, -0.2412, -0.7338],\n",
      "        [ 2.7083, -0.0967, -1.2441, -4.6382],\n",
      "        [-0.1497, -0.5492, -0.0295, -0.0747],\n",
      "        ...,\n",
      "        [-5.1566,  0.2363,  1.8914,  0.1567],\n",
      "        [-3.0591, -0.2963, -0.6630,  2.4975],\n",
      "        [ 4.7289, -2.5365, -2.8355, -4.3988]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.7326e-01, -1.6234e+00, -1.3327e+00, -1.8253e+00],\n",
      "        [-7.7296e-02, -2.8823e+00, -4.0297e+00, -7.4238e+00],\n",
      "        [-1.3549e+00, -1.7544e+00, -1.2347e+00, -1.2798e+00],\n",
      "        ...,\n",
      "        [-7.3616e+00, -1.9687e+00, -3.1365e-01, -2.0483e+00],\n",
      "        [-5.6587e+00, -2.8959e+00, -3.2625e+00, -1.0207e-01],\n",
      "        [-1.3256e-03, -7.2667e+00, -7.5657e+00, -9.1290e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6659\n",
      "x tensor([[ 0.0639, -0.3834, -0.3031, -0.7307],\n",
      "        [ 2.6895,  0.0740, -1.3146, -4.7749],\n",
      "        [-0.1957, -0.4343, -0.0744, -0.0607],\n",
      "        ...,\n",
      "        [-5.2272,  0.3533,  1.8595,  0.1372],\n",
      "        [-3.1826, -0.1600, -0.7328,  2.5647],\n",
      "        [ 4.6601, -2.3454, -2.9567, -4.3937]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0238e+00, -1.4712e+00, -1.3909e+00, -1.8185e+00],\n",
      "        [-8.7962e-02, -2.7034e+00, -4.0920e+00, -7.5524e+00],\n",
      "        [-1.4015e+00, -1.6401e+00, -1.2802e+00, -1.2665e+00],\n",
      "        ...,\n",
      "        [-7.4240e+00, -1.8435e+00, -3.3737e-01, -2.0596e+00],\n",
      "        [-5.8478e+00, -2.8252e+00, -3.3981e+00, -1.0051e-01],\n",
      "        [-1.5147e-03, -7.0071e+00, -7.6183e+00, -9.0554e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6592\n",
      "x tensor([[ 0.1969, -0.4978, -0.3840, -0.6031],\n",
      "        [ 2.9880, -0.1623, -1.4085, -4.8475],\n",
      "        [-0.0949, -0.5276, -0.1344,  0.0339],\n",
      "        ...,\n",
      "        [-5.1026,  0.2266,  1.7992,  0.2188],\n",
      "        [-3.0227, -0.3784, -0.8113,  2.7450],\n",
      "        [ 4.9472, -2.5948, -3.1113, -4.2477]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.1944e-01, -1.6142e+00, -1.5004e+00, -1.7195e+00],\n",
      "        [-5.4064e-02, -3.2044e+00, -4.4506e+00, -7.8896e+00],\n",
      "        [-1.3211e+00, -1.7538e+00, -1.3606e+00, -1.1923e+00],\n",
      "        ...,\n",
      "        [-7.2485e+00, -1.9193e+00, -3.4671e-01, -1.9271e+00],\n",
      "        [-5.8407e+00, -3.1963e+00, -3.6292e+00, -7.2953e-02],\n",
      "        [-9.4786e-04, -7.5429e+00, -8.0595e+00, -9.1959e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6539\n",
      "x tensor([[ 0.1059, -0.3566, -0.3538, -0.7282],\n",
      "        [ 2.9462,  0.0066, -1.3975, -5.1420],\n",
      "        [-0.1712, -0.4188, -0.1043, -0.0530],\n",
      "        ...,\n",
      "        [-5.2053,  0.3300,  1.8643,  0.0760],\n",
      "        [-3.1754, -0.2635, -0.7584,  2.6622],\n",
      "        [ 4.8414, -2.4434, -3.0935, -4.4322]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.9156e-01, -1.4540e+00, -1.4513e+00, -1.8257e+00],\n",
      "        [-6.4085e-02, -3.0037e+00, -4.4078e+00, -8.1522e+00],\n",
      "        [-1.3801e+00, -1.6277e+00, -1.3132e+00, -1.2619e+00],\n",
      "        ...,\n",
      "        [-7.3943e+00, -1.8591e+00, -3.2475e-01, -2.1130e+00],\n",
      "        [-5.9230e+00, -3.0111e+00, -3.5060e+00, -8.5479e-02],\n",
      "        [-1.1370e-03, -7.2860e+00, -7.9360e+00, -9.2747e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6469\n",
      "x tensor([[ 6.8623e-02, -5.3922e-01, -2.4656e-01, -6.6290e-01],\n",
      "        [ 2.9877e+00, -2.4220e-01, -1.3022e+00, -5.2310e+00],\n",
      "        [-2.1142e-01, -5.6175e-01, -1.0302e-02, -3.5906e-03],\n",
      "        ...,\n",
      "        [-5.2665e+00,  1.3644e-01,  1.9831e+00,  8.6534e-02],\n",
      "        [-3.2547e+00, -5.7828e-01, -5.9641e-01,  2.7840e+00],\n",
      "        [ 4.8548e+00, -2.8226e+00, -2.9627e+00, -4.3468e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0135e+00, -1.6214e+00, -1.3287e+00, -1.7451e+00],\n",
      "        [-5.2156e-02, -3.2820e+00, -4.3420e+00, -8.2708e+00],\n",
      "        [-1.4251e+00, -1.7754e+00, -1.2240e+00, -1.2173e+00],\n",
      "        ...,\n",
      "        [-7.5185e+00, -2.1156e+00, -2.6893e-01, -2.1655e+00],\n",
      "        [-6.1074e+00, -3.4310e+00, -3.4491e+00, -6.8660e-02],\n",
      "        [-9.6620e-04, -7.6783e+00, -7.8185e+00, -9.2025e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6416\n",
      "x tensor([[ 0.1234, -0.3948, -0.3716, -0.7039],\n",
      "        [ 3.0479, -0.0733, -1.4361, -5.4025],\n",
      "        [-0.1749, -0.4413, -0.1064, -0.0373],\n",
      "        ...,\n",
      "        [-5.2733,  0.2524,  1.9064,  0.0505],\n",
      "        [-3.2871, -0.4277, -0.7323,  2.7746],\n",
      "        [ 5.0047, -2.7215, -3.1650, -4.4191]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.7169e-01, -1.4899e+00, -1.4667e+00, -1.7990e+00],\n",
      "        [-5.4116e-02, -3.1753e+00, -4.5381e+00, -8.5045e+00],\n",
      "        [-1.3825e+00, -1.6489e+00, -1.3139e+00, -1.2448e+00],\n",
      "        ...,\n",
      "        [-7.4786e+00, -1.9529e+00, -2.9890e-01, -2.1548e+00],\n",
      "        [-6.1321e+00, -3.2728e+00, -3.5773e+00, -7.0448e-02],\n",
      "        [-8.0470e-04, -7.7270e+00, -8.1705e+00, -9.4246e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6345\n",
      "x tensor([[ 0.1938, -0.5271, -0.3998, -0.5975],\n",
      "        [ 3.2054, -0.3105, -1.4640, -5.4266],\n",
      "        [-0.1266, -0.5440, -0.1243,  0.0366],\n",
      "        ...,\n",
      "        [-5.2646,  0.1196,  1.9029,  0.1220],\n",
      "        [-3.2812, -0.6395, -0.7207,  2.9183],\n",
      "        [ 5.1872, -3.0331, -3.2268, -4.2887]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.1305e-01, -1.6339e+00, -1.5067e+00, -1.7043e+00],\n",
      "        [-3.8525e-02, -3.5544e+00, -4.7080e+00, -8.6705e+00],\n",
      "        [-1.3450e+00, -1.7625e+00, -1.3427e+00, -1.1818e+00],\n",
      "        ...,\n",
      "        [-7.4582e+00, -2.0740e+00, -2.9068e-01, -2.0716e+00],\n",
      "        [-6.2548e+00, -3.6131e+00, -3.6943e+00, -5.5255e-02],\n",
      "        [-5.6739e-04, -8.2208e+00, -8.4146e+00, -9.4764e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6292\n",
      "x tensor([[ 0.0512, -0.4056, -0.3246, -0.7268],\n",
      "        [ 3.0541, -0.1504, -1.3938, -5.6748],\n",
      "        [-0.2426, -0.4515, -0.0613, -0.0495],\n",
      "        ...,\n",
      "        [-5.4641,  0.2238,  2.0156, -0.0191],\n",
      "        [-3.5540, -0.5269, -0.6077,  2.8275],\n",
      "        [ 5.0186, -2.8985, -3.1259, -4.5056]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0223e+00, -1.4790e+00, -1.3980e+00, -1.8002e+00],\n",
      "        [-5.1117e-02, -3.2556e+00, -4.4990e+00, -8.7799e+00],\n",
      "        [-1.4406e+00, -1.6495e+00, -1.2593e+00, -1.2475e+00],\n",
      "        ...,\n",
      "        [-7.7405e+00, -2.0525e+00, -2.6079e-01, -2.2955e+00],\n",
      "        [-6.4481e+00, -3.4210e+00, -3.5018e+00, -6.6576e-02],\n",
      "        [-7.2763e-04, -7.9178e+00, -8.1452e+00, -9.5249e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6230\n",
      "x tensor([[ 1.3516e-01, -6.0184e-01, -2.9966e-01, -6.4938e-01],\n",
      "        [ 3.2974e+00, -4.8664e-01, -1.3607e+00, -5.7514e+00],\n",
      "        [-1.8538e-01, -6.0829e-01, -3.8313e-02,  8.8787e-03],\n",
      "        ...,\n",
      "        [-5.3797e+00,  1.7531e-02,  2.0619e+00, -4.7795e-03],\n",
      "        [-3.4340e+00, -8.4883e-01, -5.2526e-01,  2.9128e+00],\n",
      "        [ 5.1941e+00, -3.2905e+00, -3.1044e+00, -4.4314e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.4866e-01, -1.6857e+00, -1.3835e+00, -1.7332e+00],\n",
      "        [-3.1822e-02, -3.8158e+00, -4.6899e+00, -9.0806e+00],\n",
      "        [-1.3933e+00, -1.8162e+00, -1.2462e+00, -1.1990e+00],\n",
      "        ...,\n",
      "        [-7.6701e+00, -2.2728e+00, -2.2845e-01, -2.2951e+00],\n",
      "        [-6.4023e+00, -3.8171e+00, -3.4936e+00, -5.5555e-02],\n",
      "        [-5.2140e-04, -8.4852e+00, -8.2990e+00, -9.6261e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6177\n",
      "x tensor([[ 0.1315, -0.3765, -0.4251, -0.7019],\n",
      "        [ 3.2649, -0.1824, -1.4818, -5.9091],\n",
      "        [-0.1954, -0.4294, -0.1390, -0.0148],\n",
      "        ...,\n",
      "        [-5.4233,  0.2120,  1.9885, -0.0479],\n",
      "        [-3.5124, -0.5962, -0.6657,  2.8760],\n",
      "        [ 5.2090, -3.0094, -3.2902, -4.5369]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.5913e-01, -1.4671e+00, -1.5157e+00, -1.7926e+00],\n",
      "        [-3.9813e-02, -3.4871e+00, -4.7865e+00, -9.2139e+00],\n",
      "        [-1.3981e+00, -1.6320e+00, -1.3416e+00, -1.2175e+00],\n",
      "        ...,\n",
      "        [-7.6744e+00, -2.0391e+00, -2.6263e-01, -2.2990e+00],\n",
      "        [-6.4482e+00, -3.5320e+00, -3.6016e+00, -5.9866e-02],\n",
      "        [-5.3165e-04, -8.2189e+00, -8.4997e+00, -9.7464e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6124\n",
      "x tensor([[ 0.1715, -0.6648, -0.3524, -0.5091],\n",
      "        [ 3.4333, -0.6183, -1.4015, -5.8344],\n",
      "        [-0.1767, -0.6564, -0.0740,  0.1327],\n",
      "        ...,\n",
      "        [-5.3919, -0.0631,  2.0672,  0.0867],\n",
      "        [-3.4577, -1.0398, -0.5394,  3.1045],\n",
      "        [ 5.3437, -3.5557, -3.1932, -4.3022]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.2895e-01, -1.7652e+00, -1.4528e+00, -1.6095e+00],\n",
      "        [-2.5119e-02, -4.0767e+00, -4.8599e+00, -9.2929e+00],\n",
      "        [-1.4085e+00, -1.8882e+00, -1.3058e+00, -1.0991e+00],\n",
      "        ...,\n",
      "        [-7.6881e+00, -2.3593e+00, -2.2903e-01, -2.2095e+00],\n",
      "        [-6.6047e+00, -4.1868e+00, -3.6864e+00, -4.2502e-02],\n",
      "        [-3.9725e-04, -8.8998e+00, -8.5374e+00, -9.6463e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6077\n",
      "x tensor([[ 0.0537, -0.3525, -0.3093, -0.8327],\n",
      "        [ 3.2829, -0.2382, -1.3765, -6.2646],\n",
      "        [-0.2681, -0.4181, -0.0380, -0.0971],\n",
      "        ...,\n",
      "        [-5.5767,  0.2279,  2.1629, -0.1668],\n",
      "        [-3.6942, -0.7026, -0.5166,  2.8566],\n",
      "        [ 5.2039, -3.1725, -3.1189, -4.7950]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-1.0203e+00, -1.4265e+00, -1.3833e+00, -1.9066e+00],\n",
      "        [-3.8366e-02, -3.5594e+00, -4.6977e+00, -9.5858e+00],\n",
      "        [-1.4600e+00, -1.6100e+00, -1.2299e+00, -1.2890e+00],\n",
      "        ...,\n",
      "        [-7.9565e+00, -2.1519e+00, -2.1686e-01, -2.5466e+00],\n",
      "        [-6.6129e+00, -3.6213e+00, -3.4353e+00, -6.2200e-02],\n",
      "        [-5.1843e-04, -8.3769e+00, -8.3234e+00, -9.9994e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.6031\n",
      "x tensor([[ 0.2274, -0.6967, -0.3283, -0.5679],\n",
      "        [ 3.6247, -0.7893, -1.3791, -6.1299],\n",
      "        [-0.1449, -0.6806, -0.0444,  0.0843],\n",
      "        ...,\n",
      "        [-5.4299, -0.1019,  2.1541,  0.0422],\n",
      "        [-3.4682, -1.2081, -0.5024,  3.1337],\n",
      "        [ 5.5675, -3.8900, -3.1462, -4.4552]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.8462e-01, -1.8086e+00, -1.4403e+00, -1.6799e+00],\n",
      "        [-1.8700e-02, -4.4328e+00, -5.0226e+00, -9.7733e+00],\n",
      "        [-1.3733e+00, -1.9090e+00, -1.2729e+00, -1.1442e+00],\n",
      "        ...,\n",
      "        [-7.7880e+00, -2.4601e+00, -2.0398e-01, -2.3159e+00],\n",
      "        [-6.6418e+00, -4.3817e+00, -3.6761e+00, -3.9917e-02],\n",
      "        [-2.8666e-04, -9.4578e+00, -8.7140e+00, -1.0023e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5977\n",
      "x tensor([[ 0.1054, -0.3629, -0.4053, -0.7081],\n",
      "        [ 3.3125, -0.2534, -1.4524, -6.3247],\n",
      "        [-0.2445, -0.4166, -0.1063, -0.0081],\n",
      "        ...,\n",
      "        [-5.6678,  0.1970,  2.1332, -0.0378],\n",
      "        [-3.8002, -0.8008, -0.5976,  3.0609],\n",
      "        [ 5.4099, -3.4627, -3.2437, -4.6608]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.8190e-01, -1.4502e+00, -1.4926e+00, -1.7953e+00],\n",
      "        [-3.6197e-02, -3.6021e+00, -4.8011e+00, -9.6734e+00],\n",
      "        [-1.4485e+00, -1.6206e+00, -1.3103e+00, -1.2121e+00],\n",
      "        ...,\n",
      "        [-8.0312e+00, -2.1663e+00, -2.3009e-01, -2.4012e+00],\n",
      "        [-6.9079e+00, -3.9085e+00, -3.7053e+00, -4.6739e-02],\n",
      "        [-3.5697e-04, -8.8730e+00, -8.6540e+00, -1.0071e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5901\n",
      "x tensor([[ 0.1820, -0.6128, -0.3333, -0.6334],\n",
      "        [ 3.5264, -0.6143, -1.3498, -6.4106],\n",
      "        [-0.1938, -0.6115, -0.0443,  0.0477],\n",
      "        ...,\n",
      "        [-5.5491, -0.0587,  2.2081,  0.0082],\n",
      "        [-3.6308, -1.2170, -0.4733,  3.1510],\n",
      "        [ 5.5937, -4.0083, -3.1322, -4.5775]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.1286e-01, -1.7077e+00, -1.4282e+00, -1.7283e+00],\n",
      "        [-2.3312e-02, -4.1640e+00, -4.8996e+00, -9.9604e+00],\n",
      "        [-1.4093e+00, -1.8270e+00, -1.2597e+00, -1.1678e+00],\n",
      "        ...,\n",
      "        [-7.9519e+00, -2.4615e+00, -1.9464e-01, -2.3946e+00],\n",
      "        [-6.8215e+00, -4.4077e+00, -3.6640e+00, -3.9680e-02],\n",
      "        [-2.6818e-04, -9.6023e+00, -8.7261e+00, -1.0171e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5815\n",
      "x tensor([[ 0.1481, -0.5352, -0.3252, -0.7391],\n",
      "        [ 3.4906, -0.4716, -1.3238, -6.6750],\n",
      "        [-0.2199, -0.5571, -0.0403, -0.0161],\n",
      "        ...,\n",
      "        [-5.5914, -0.0120,  2.2411, -0.0687],\n",
      "        [-3.6915, -1.1847, -0.4497,  3.0869],\n",
      "        [ 5.5669, -3.9876, -3.1066, -4.7462]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.3204e-01, -1.6154e+00, -1.4053e+00, -1.8192e+00],\n",
      "        [-2.6808e-02, -3.9891e+00, -4.8413e+00, -1.0192e+01],\n",
      "        [-1.4199e+00, -1.7571e+00, -1.2402e+00, -1.2161e+00],\n",
      "        ...,\n",
      "        [-8.0188e+00, -2.4394e+00, -1.8627e-01, -2.4961e+00],\n",
      "        [-6.8216e+00, -4.3149e+00, -3.5799e+00, -4.3261e-02],\n",
      "        [-2.7510e-04, -9.5548e+00, -8.6738e+00, -1.0313e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5749\n",
      "x tensor([[ 0.1178, -0.4655, -0.3993, -0.6789],\n",
      "        [ 3.3843, -0.3181, -1.3726, -6.7276],\n",
      "        [-0.2443, -0.5052, -0.1018,  0.0421],\n",
      "        ...,\n",
      "        [-5.6956,  0.0316,  2.1919,  0.0082],\n",
      "        [-3.8527, -1.1137, -0.5125,  3.1919],\n",
      "        [ 5.5530, -3.9806, -3.2034, -4.6716]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.5748e-01, -1.5408e+00, -1.4746e+00, -1.7542e+00],\n",
      "        [-3.2755e-02, -3.7351e+00, -4.7896e+00, -1.0145e+01],\n",
      "        [-1.4481e+00, -1.7090e+00, -1.3057e+00, -1.1617e+00],\n",
      "        ...,\n",
      "        [-8.0932e+00, -2.3659e+00, -2.0562e-01, -2.3894e+00],\n",
      "        [-7.0828e+00, -4.3439e+00, -3.7427e+00, -3.8237e-02],\n",
      "        [-2.6604e-04, -9.5338e+00, -8.7567e+00, -1.0225e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5695\n",
      "x tensor([[ 0.1849, -0.6405, -0.3727, -0.5899],\n",
      "        [ 3.5611, -0.6321, -1.3236, -6.7543],\n",
      "        [-0.1987, -0.6411, -0.0751,  0.1081],\n",
      "        ...,\n",
      "        [-5.6533, -0.1348,  2.2261,  0.0751],\n",
      "        [-3.7863, -1.3933, -0.4687,  3.3138],\n",
      "        [ 5.7426, -4.4424, -3.1562, -4.5731]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.0479e-01, -1.7302e+00, -1.4624e+00, -1.6796e+00],\n",
      "        [-2.2439e-02, -4.2156e+00, -4.9072e+00, -1.0338e+01],\n",
      "        [-1.4190e+00, -1.8614e+00, -1.2954e+00, -1.1122e+00],\n",
      "        ...,\n",
      "        [-8.0709e+00, -2.5524e+00, -1.9152e-01, -2.3425e+00],\n",
      "        [-7.1322e+00, -4.7392e+00, -3.8147e+00, -3.2099e-02],\n",
      "        [-2.0740e-04, -1.0185e+01, -8.8991e+00, -1.0316e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5648\n",
      "x tensor([[ 0.0868, -0.3778, -0.3164, -0.9023],\n",
      "        [ 3.3692, -0.2561, -1.2831, -7.1393],\n",
      "        [-0.2776, -0.4360, -0.0256, -0.1174],\n",
      "        ...,\n",
      "        [-5.8213,  0.1019,  2.3282, -0.1744],\n",
      "        [-4.0256, -1.1048, -0.4539,  3.1076],\n",
      "        [ 5.6305, -4.1544, -3.0554, -5.0333]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.8152e-01, -1.4461e+00, -1.3847e+00, -1.9706e+00],\n",
      "        [-3.5566e-02, -3.6609e+00, -4.6879e+00, -1.0544e+01],\n",
      "        [-1.4618e+00, -1.6203e+00, -1.2098e+00, -1.3016e+00],\n",
      "        ...,\n",
      "        [-8.3236e+00, -2.4003e+00, -1.7403e-01, -2.6766e+00],\n",
      "        [-7.1762e+00, -4.2555e+00, -3.6046e+00, -4.3063e-02],\n",
      "        [-2.4852e-04, -9.7851e+00, -8.6862e+00, -1.0664e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5613\n",
      "x tensor([[ 0.2181, -0.7355, -0.3440, -0.5335],\n",
      "        [ 3.6089, -0.7747, -1.2721, -6.8490],\n",
      "        [-0.1896, -0.7082, -0.0360,  0.1476],\n",
      "        ...,\n",
      "        [-5.7133, -0.2289,  2.2917,  0.1024],\n",
      "        [-3.8951, -1.5757, -0.4499,  3.4627],\n",
      "        [ 5.9244, -4.8757, -3.0943, -4.5383]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.8667e-01, -1.8402e+00, -1.4488e+00, -1.6382e+00],\n",
      "        [-1.9901e-02, -4.4034e+00, -4.9008e+00, -1.0478e+01],\n",
      "        [-1.4261e+00, -1.9447e+00, -1.2725e+00, -1.0889e+00],\n",
      "        ...,\n",
      "        [-8.1812e+00, -2.6968e+00, -1.7626e-01, -2.3655e+00],\n",
      "        [-7.3846e+00, -5.0652e+00, -3.9394e+00, -2.6748e-02],\n",
      "        [-1.7010e-04, -1.0800e+01, -9.0188e+00, -1.0463e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5572\n",
      "x tensor([[ 0.1055, -0.3348, -0.3934, -0.8235],\n",
      "        [ 3.3155, -0.1217, -1.3291, -7.2457],\n",
      "        [-0.2749, -0.4007, -0.0778, -0.0488],\n",
      "        ...,\n",
      "        [-5.9070,  0.1363,  2.2951, -0.1330],\n",
      "        [-4.2051, -1.0550, -0.5350,  3.2328],\n",
      "        [ 5.7194, -4.2602, -3.1478, -4.9664]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.7307e-01, -1.4133e+00, -1.4719e+00, -1.9020e+00],\n",
      "        [-4.0944e-02, -3.4781e+00, -4.6856e+00, -1.0602e+01],\n",
      "        [-1.4709e+00, -1.5967e+00, -1.2739e+00, -1.2449e+00],\n",
      "        ...,\n",
      "        [-8.3877e+00, -2.3444e+00, -1.8560e-01, -2.6137e+00],\n",
      "        [-7.4747e+00, -4.3246e+00, -3.8046e+00, -3.6742e-02],\n",
      "        [-2.1014e-04, -9.9798e+00, -8.8674e+00, -1.0686e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5506\n",
      "x tensor([[ 2.0590e-01, -7.0437e-01, -3.0706e-01, -6.3501e-01],\n",
      "        [ 3.6335e+00, -7.0818e-01, -1.1866e+00, -7.2193e+00],\n",
      "        [-2.0334e-01, -6.9714e-01, -3.5568e-03,  1.0098e-01],\n",
      "        ...,\n",
      "        [-5.7267e+00, -2.1472e-01,  2.3530e+00, -1.8888e-02],\n",
      "        [-4.0064e+00, -1.5703e+00, -3.9608e-01,  3.4131e+00],\n",
      "        [ 5.9504e+00, -4.9821e+00, -3.0118e+00, -4.7710e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.8890e-01, -1.7992e+00, -1.4019e+00, -1.7298e+00],\n",
      "        [-2.0881e-02, -4.3626e+00, -4.8410e+00, -1.0874e+01],\n",
      "        [-1.4320e+00, -1.9258e+00, -1.2322e+00, -1.1277e+00],\n",
      "        ...,\n",
      "        [-8.2370e+00, -2.7250e+00, -1.5728e-01, -2.5292e+00],\n",
      "        [-7.4487e+00, -5.0126e+00, -3.8384e+00, -2.9186e-02],\n",
      "        [-1.6807e-04, -1.0933e+01, -8.9624e+00, -1.0722e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5431\n",
      "x tensor([[ 9.7655e-02, -4.6980e-01, -3.2906e-01, -7.8292e-01],\n",
      "        [ 3.3730e+00, -3.1768e-01, -1.1798e+00, -7.4712e+00],\n",
      "        [-2.8747e-01, -5.2197e-01, -2.5420e-02,  2.0684e-02],\n",
      "        ...,\n",
      "        [-5.8964e+00, -4.1793e-03,  2.3511e+00, -1.1070e-01],\n",
      "        [-4.3242e+00, -1.2612e+00, -4.2545e-01,  3.3540e+00],\n",
      "        [ 5.7975e+00, -4.6839e+00, -3.0194e+00, -5.0252e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.6857e-01, -1.5360e+00, -1.3953e+00, -1.8491e+00],\n",
      "        [-3.4897e-02, -3.7256e+00, -4.5877e+00, -1.0879e+01],\n",
      "        [-1.4932e+00, -1.7277e+00, -1.2312e+00, -1.1851e+00],\n",
      "        ...,\n",
      "        [-8.4134e+00, -2.5212e+00, -1.6586e-01, -2.6277e+00],\n",
      "        [-7.7109e+00, -4.6479e+00, -3.8121e+00, -3.2658e-02],\n",
      "        [-1.9608e-04, -1.0482e+01, -8.8172e+00, -1.0823e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5342\n",
      "x tensor([[ 0.1609, -0.5098, -0.4084, -0.6842],\n",
      "        [ 3.4526, -0.4117, -1.2114, -7.4933],\n",
      "        [-0.2418, -0.5551, -0.0885,  0.1031],\n",
      "        ...,\n",
      "        [-5.8721, -0.0484,  2.2779, -0.0216],\n",
      "        [-4.3737, -1.2901, -0.4934,  3.4832],\n",
      "        [ 5.9601, -4.9042, -3.1150, -4.9383]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.1899e-01, -1.5897e+00, -1.4883e+00, -1.7641e+00],\n",
      "        [-2.9971e-02, -3.8943e+00, -4.6939e+00, -1.0976e+01],\n",
      "        [-1.4606e+00, -1.7739e+00, -1.3073e+00, -1.1157e+00],\n",
      "        ...,\n",
      "        [-8.3309e+00, -2.5072e+00, -1.8087e-01, -2.4803e+00],\n",
      "        [-7.8842e+00, -4.8005e+00, -4.0039e+00, -2.7214e-02],\n",
      "        [-1.5198e-04, -1.0864e+01, -9.0752e+00, -1.0899e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5279\n",
      "x tensor([[ 0.1814, -0.6052, -0.3289, -0.7206],\n",
      "        [ 3.5829, -0.6478, -1.1165, -7.6564],\n",
      "        [-0.2329, -0.6311, -0.0153,  0.0710],\n",
      "        ...,\n",
      "        [-5.8464, -0.1317,  2.3649, -0.0783],\n",
      "        [-4.3956, -1.4373, -0.4244,  3.5095],\n",
      "        [ 6.0665, -5.2108, -2.9785, -5.0384]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.0073e-01, -1.6874e+00, -1.4110e+00, -1.8028e+00],\n",
      "        [-2.3380e-02, -4.2541e+00, -4.7228e+00, -1.1263e+01],\n",
      "        [-1.4515e+00, -1.8498e+00, -1.2340e+00, -1.1476e+00],\n",
      "        ...,\n",
      "        [-8.3680e+00, -2.6532e+00, -1.5659e-01, -2.5998e+00],\n",
      "        [-7.9318e+00, -4.9735e+00, -3.9606e+00, -2.6683e-02],\n",
      "        [-1.4566e-04, -1.1277e+01, -9.0451e+00, -1.1105e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5227\n",
      "x tensor([[ 6.6273e-02, -3.9865e-01, -3.1330e-01, -8.7570e-01],\n",
      "        [ 3.3011e+00, -2.7743e-01, -1.1021e+00, -7.8706e+00],\n",
      "        [-3.2946e-01, -4.6933e-01,  2.8912e-03, -3.8826e-02],\n",
      "        ...,\n",
      "        [-6.0393e+00,  6.8439e-02,  2.4196e+00, -2.0181e-01],\n",
      "        [-4.7364e+00, -1.1674e+00, -4.3815e-01,  3.4657e+00],\n",
      "        [ 5.8768e+00, -4.8664e+00, -2.9346e+00, -5.2492e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.9406e-01, -1.4590e+00, -1.3736e+00, -1.9360e+00],\n",
      "        [-3.9383e-02, -3.6179e+00, -4.4426e+00, -1.1211e+01],\n",
      "        [-1.5263e+00, -1.6661e+00, -1.1939e+00, -1.2356e+00],\n",
      "        ...,\n",
      "        [-8.6143e+00, -2.5066e+00, -1.5544e-01, -2.7768e+00],\n",
      "        [-8.2318e+00, -4.6628e+00, -3.9335e+00, -2.9718e-02],\n",
      "        [-1.8535e-04, -1.0743e+01, -8.8116e+00, -1.1126e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5188\n",
      "x tensor([[ 0.2457, -0.7086, -0.3966, -0.5624],\n",
      "        [ 3.6486, -0.7924, -1.1229, -7.6586],\n",
      "        [-0.2022, -0.7057, -0.0553,  0.1839],\n",
      "        ...,\n",
      "        [-5.8069, -0.2373,  2.3148,  0.0278],\n",
      "        [-4.5046, -1.5592, -0.4931,  3.7377],\n",
      "        [ 6.2150, -5.4772, -3.0587, -4.8210]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.5733e-01, -1.8116e+00, -1.4996e+00, -1.6655e+00],\n",
      "        [-2.0062e-02, -4.4611e+00, -4.7915e+00, -1.1327e+01],\n",
      "        [-1.4431e+00, -1.9466e+00, -1.2962e+00, -1.0570e+00],\n",
      "        ...,\n",
      "        [-8.2871e+00, -2.7174e+00, -1.6533e-01, -2.4524e+00],\n",
      "        [-8.2619e+00, -5.3165e+00, -4.2504e+00, -1.9617e-02],\n",
      "        [-1.1825e-04, -1.1692e+01, -9.2739e+00, -1.1036e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5161\n",
      "x tensor([[ 0.0935, -0.3113, -0.3495, -0.9951],\n",
      "        [ 3.3519, -0.1871, -1.0836, -8.2223],\n",
      "        [-0.3187, -0.4040, -0.0199, -0.1170],\n",
      "        ...,\n",
      "        [-5.9952,  0.1222,  2.4171, -0.3319],\n",
      "        [-4.8260, -1.0837, -0.4926,  3.4265],\n",
      "        [ 5.9350, -4.8458, -2.9531, -5.4754]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.7300e-01, -1.3778e+00, -1.4160e+00, -2.0616e+00],\n",
      "        [-4.0087e-02, -3.5791e+00, -4.4756e+00, -1.1614e+01],\n",
      "        [-1.5018e+00, -1.5872e+00, -1.2030e+00, -1.3002e+00],\n",
      "        ...,\n",
      "        [-8.5650e+00, -2.4476e+00, -1.5271e-01, -2.9017e+00],\n",
      "        [-8.2832e+00, -4.5409e+00, -3.9498e+00, -3.0641e-02],\n",
      "        [-1.6986e-04, -1.0781e+01, -8.8883e+00, -1.1411e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5114\n",
      "x tensor([[ 1.7590e-01, -7.5990e-01, -3.0823e-01, -5.9597e-01],\n",
      "        [ 3.6124e+00, -9.3099e-01, -9.4991e-01, -7.9211e+00],\n",
      "        [-2.6351e-01, -7.5651e-01,  1.7444e-02,  1.8616e-01],\n",
      "        ...,\n",
      "        [-5.8973e+00, -2.7891e-01,  2.4103e+00, -7.7719e-03],\n",
      "        [-4.7772e+00, -1.6377e+00, -3.9126e-01,  3.8239e+00],\n",
      "        [ 6.1776e+00, -5.7252e+00, -2.8831e+00, -4.9985e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.0448e-01, -1.8403e+00, -1.3886e+00, -1.6763e+00],\n",
      "        [-2.0865e-02, -4.5643e+00, -4.5832e+00, -1.1554e+01],\n",
      "        [-1.5047e+00, -1.9977e+00, -1.2238e+00, -1.0551e+00],\n",
      "        ...,\n",
      "        [-8.4536e+00, -2.8353e+00, -1.4607e-01, -2.5641e+00],\n",
      "        [-8.6201e+00, -5.4806e+00, -4.2342e+00, -1.9019e-02],\n",
      "        [-1.3684e-04, -1.1903e+01, -9.0609e+00, -1.1176e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.5064\n",
      "x tensor([[ 0.1179, -0.3363, -0.3936, -0.9450],\n",
      "        [ 3.3975, -0.3187, -1.0254, -8.4196],\n",
      "        [-0.3041, -0.4338, -0.0585, -0.0495],\n",
      "        ...,\n",
      "        [-6.0237,  0.0860,  2.3737, -0.2615],\n",
      "        [-5.0150, -1.1076, -0.5351,  3.5846],\n",
      "        [ 6.0572, -5.0700, -2.9730, -5.5186]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.4780e-01, -1.4020e+00, -1.4593e+00, -2.0107e+00],\n",
      "        [-3.5689e-02, -3.7518e+00, -4.4586e+00, -1.1853e+01],\n",
      "        [-1.4922e+00, -1.6219e+00, -1.2466e+00, -1.2375e+00],\n",
      "        ...,\n",
      "        [-8.5573e+00, -2.4476e+00, -1.5993e-01, -2.7951e+00],\n",
      "        [-8.6249e+00, -4.7175e+00, -4.1450e+00, -2.5278e-02],\n",
      "        [-1.4376e-04, -1.1127e+01, -9.0304e+00, -1.1576e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4968\n",
      "x tensor([[ 0.2014, -0.5846, -0.3754, -0.7588],\n",
      "        [ 3.6240, -0.7733, -0.9318, -8.3671],\n",
      "        [-0.2481, -0.6257, -0.0373,  0.0907],\n",
      "        ...,\n",
      "        [-5.8994, -0.1387,  2.3757, -0.1389],\n",
      "        [-4.9275, -1.4254, -0.4883,  3.7638],\n",
      "        [ 6.2805, -5.6144, -2.9216, -5.3124]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.7555e-01, -1.6615e+00, -1.4524e+00, -1.8357e+00],\n",
      "        [-2.2565e-02, -4.4199e+00, -4.5784e+00, -1.2014e+01],\n",
      "        [-1.4640e+00, -1.8417e+00, -1.2533e+00, -1.1252e+00],\n",
      "        ...,\n",
      "        [-8.4253e+00, -2.6646e+00, -1.5019e-01, -2.6648e+00],\n",
      "        [-8.7111e+00, -5.2089e+00, -4.2719e+00, -1.9782e-02],\n",
      "        [-1.1682e-04, -1.1895e+01, -9.2022e+00, -1.1593e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4884\n",
      "x tensor([[ 0.1041, -0.5249, -0.3113, -0.8187],\n",
      "        [ 3.4359, -0.6542, -0.8485, -8.5155],\n",
      "        [-0.3288, -0.5839,  0.0194,  0.0529],\n",
      "        ...,\n",
      "        [-6.0363, -0.0692,  2.4616, -0.2048],\n",
      "        [-5.1842, -1.3538, -0.4328,  3.7929],\n",
      "        [ 6.1448, -5.5277, -2.8102, -5.4221]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.5191e-01, -1.5808e+00, -1.3673e+00, -1.8747e+00],\n",
      "        [-3.0069e-02, -4.1202e+00, -4.3145e+00, -1.1982e+01],\n",
      "        [-1.5382e+00, -1.7933e+00, -1.1900e+00, -1.1564e+00],\n",
      "        ...,\n",
      "        [-8.6371e+00, -2.6700e+00, -1.3915e-01, -2.8056e+00],\n",
      "        [-8.9974e+00, -5.1671e+00, -4.2460e+00, -2.0352e-02],\n",
      "        [-1.4709e-04, -1.1673e+01, -8.9552e+00, -1.1567e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4821\n",
      "x tensor([[ 1.6555e-01, -4.1650e-01, -4.0342e-01, -8.9375e-01],\n",
      "        [ 3.5076e+00, -5.4007e-01, -9.1581e-01, -8.7176e+00],\n",
      "        [-2.8053e-01, -5.0482e-01, -5.3485e-02,  2.7618e-03],\n",
      "        ...,\n",
      "        [-5.9795e+00,  1.9879e-02,  2.3917e+00, -2.7980e-01],\n",
      "        [-5.1553e+00, -1.2210e+00, -5.6046e-01,  3.7429e+00],\n",
      "        [ 6.2353e+00, -5.4103e+00, -2.9413e+00, -5.5632e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.0485e-01, -1.4869e+00, -1.4738e+00, -1.9641e+00],\n",
      "        [-2.9034e-02, -4.0768e+00, -4.4525e+00, -1.2254e+01],\n",
      "        [-1.4774e+00, -1.7017e+00, -1.2503e+00, -1.1941e+00],\n",
      "        ...,\n",
      "        [-8.5220e+00, -2.5226e+00, -1.5073e-01, -2.8223e+00],\n",
      "        [-8.9186e+00, -4.9843e+00, -4.3238e+00, -2.0435e-02],\n",
      "        [-1.1968e-04, -1.1646e+01, -9.1768e+00, -1.1799e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4771\n",
      "x tensor([[ 0.2118, -0.6368, -0.3740, -0.7363],\n",
      "        [ 3.6656, -0.9720, -0.8102, -8.6213],\n",
      "        [-0.2517, -0.6758, -0.0260,  0.1229],\n",
      "        ...,\n",
      "        [-5.9253, -0.1643,  2.4051, -0.1748],\n",
      "        [-5.1441, -1.4973, -0.5118,  3.9238],\n",
      "        [ 6.3935, -5.9152, -2.8926, -5.4138]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.6379e-01, -1.7124e+00, -1.4496e+00, -1.8119e+00],\n",
      "        [-2.0847e-02, -4.6585e+00, -4.4967e+00, -1.2308e+01],\n",
      "        [-1.4729e+00, -1.8970e+00, -1.2472e+00, -1.0983e+00],\n",
      "        ...,\n",
      "        [-8.4724e+00, -2.7114e+00, -1.4203e-01, -2.7219e+00],\n",
      "        [-9.0842e+00, -5.4374e+00, -4.4518e+00, -1.6253e-02],\n",
      "        [-1.0466e-04, -1.2309e+01, -9.2861e+00, -1.1807e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4734\n",
      "x tensor([[ 0.0464, -0.3389, -0.3147, -1.0546],\n",
      "        [ 3.2883, -0.4885, -0.7366, -9.0101],\n",
      "        [-0.3825, -0.4524,  0.0249, -0.0991],\n",
      "        ...,\n",
      "        [-6.1817,  0.1289,  2.5226, -0.4401],\n",
      "        [-5.5499, -1.1271, -0.4808,  3.7629],\n",
      "        [ 6.0983, -5.4203, -2.7732, -5.8884]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.9681e-01, -1.3821e+00, -1.3580e+00, -2.0979e+00],\n",
      "        [-3.9957e-02, -3.8168e+00, -4.0648e+00, -1.2338e+01],\n",
      "        [-1.5609e+00, -1.6308e+00, -1.1535e+00, -1.2775e+00],\n",
      "        ...,\n",
      "        [-8.8381e+00, -2.5275e+00, -1.3378e-01, -3.0964e+00],\n",
      "        [-9.3345e+00, -4.9118e+00, -4.2654e+00, -2.1728e-02],\n",
      "        [-1.5639e-04, -1.1519e+01, -8.8716e+00, -1.1987e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4709\n",
      "x tensor([[ 0.2867, -0.7280, -0.4332, -0.6524],\n",
      "        [ 3.8442, -1.2813, -0.7847, -8.6767],\n",
      "        [-0.2029, -0.7440, -0.0658,  0.1832],\n",
      "        ...,\n",
      "        [-5.8637, -0.2239,  2.3670, -0.1664],\n",
      "        [-5.1674, -1.6045, -0.5744,  4.0563],\n",
      "        [ 6.6092, -6.2715, -2.9589, -5.3645]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.0659e-01, -1.8213e+00, -1.5265e+00, -1.7457e+00],\n",
      "        [-1.5590e-02, -5.1412e+00, -4.6445e+00, -1.2537e+01],\n",
      "        [-1.4352e+00, -1.9762e+00, -1.2980e+00, -1.0491e+00],\n",
      "        ...,\n",
      "        [-8.3744e+00, -2.7346e+00, -1.4377e-01, -2.6771e+00],\n",
      "        [-9.2369e+00, -5.6740e+00, -4.6439e+00, -1.3239e-02],\n",
      "        [-7.8794e-05, -1.2881e+01, -9.5681e+00, -1.1974e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4687\n",
      "x tensor([[ 6.5519e-02, -2.6705e-01, -3.5970e-01, -1.1183e+00],\n",
      "        [ 3.3359e+00, -5.1649e-01, -7.0055e-01, -9.2592e+00],\n",
      "        [-3.7497e-01, -3.9438e-01, -3.9802e-04, -1.5494e-01],\n",
      "        ...,\n",
      "        [-6.1925e+00,  2.2212e-01,  2.5371e+00, -5.7778e-01],\n",
      "        [-5.6738e+00, -1.0220e+00, -5.3585e-01,  3.7456e+00],\n",
      "        [ 6.1648e+00, -5.4212e+00, -2.8080e+00, -6.0294e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.8463e-01, -1.3172e+00, -1.4099e+00, -2.1684e+00],\n",
      "        [-3.8155e-02, -3.8905e+00, -4.0746e+00, -1.2633e+01],\n",
      "        [-1.5436e+00, -1.5630e+00, -1.1690e+00, -1.3235e+00],\n",
      "        ...,\n",
      "        [-8.8636e+00, -2.4489e+00, -1.3393e-01, -3.2488e+00],\n",
      "        [-9.4416e+00, -4.7897e+00, -4.3036e+00, -2.2157e-02],\n",
      "        [-1.4113e-04, -1.1586e+01, -8.9729e+00, -1.2194e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4633\n",
      "x tensor([[ 0.1989, -0.7456, -0.3269, -0.6915],\n",
      "        [ 3.7273, -1.4012, -0.5758, -8.8653],\n",
      "        [-0.2811, -0.7602,  0.0323,  0.1545],\n",
      "        ...,\n",
      "        [-6.0188, -0.1792,  2.5166, -0.2685],\n",
      "        [-5.4826, -1.6273, -0.4683,  4.1635],\n",
      "        [ 6.5447, -6.4155, -2.7817, -5.4837]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.7144e-01, -1.8160e+00, -1.3973e+00, -1.7619e+00],\n",
      "        [-1.9268e-02, -5.1478e+00, -4.3224e+00, -1.2612e+01],\n",
      "        [-1.5114e+00, -1.9906e+00, -1.1981e+00, -1.0758e+00],\n",
      "        ...,\n",
      "        [-8.6571e+00, -2.8175e+00, -1.2169e-01, -2.9068e+00],\n",
      "        [-9.6589e+00, -5.8035e+00, -4.6446e+00, -1.2776e-02],\n",
      "        [-9.7389e-05, -1.2960e+01, -9.3265e+00, -1.2029e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4568\n",
      "x tensor([[ 0.1895, -0.3478, -0.4430, -1.0365],\n",
      "        [ 3.5706, -0.8022, -0.6835, -9.3620],\n",
      "        [-0.2823, -0.4605, -0.0676, -0.0776],\n",
      "        ...,\n",
      "        [-6.0740,  0.1568,  2.4565, -0.5346],\n",
      "        [-5.6094, -1.1349, -0.6369,  3.9080],\n",
      "        [ 6.4762, -5.8550, -2.9366, -6.0045]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.7924e-01, -1.4166e+00, -1.5117e+00, -2.1052e+00],\n",
      "        [-2.6470e-02, -4.3993e+00, -4.2806e+00, -1.2959e+01],\n",
      "        [-1.4594e+00, -1.6376e+00, -1.2447e+00, -1.2547e+00],\n",
      "        ...,\n",
      "        [-8.6709e+00, -2.4400e+00, -1.4039e-01, -3.1315e+00],\n",
      "        [-9.5344e+00, -5.0599e+00, -4.5619e+00, -1.7005e-02],\n",
      "        [-8.9880e-05, -1.2331e+01, -9.4130e+00, -1.2481e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4466\n",
      "x tensor([[ 1.4522e-01, -5.1565e-01, -3.5664e-01, -9.3259e-01],\n",
      "        [ 3.5890e+00, -1.1399e+00, -5.2760e-01, -9.3297e+00],\n",
      "        [-3.2014e-01, -5.9849e-01, -5.8528e-04,  1.5385e-02],\n",
      "        ...,\n",
      "        [-6.1522e+00,  3.3730e-02,  2.5260e+00, -4.4579e-01],\n",
      "        [-5.7698e+00, -1.3546e+00, -5.1162e-01,  4.0934e+00],\n",
      "        [ 6.4680e+00, -6.3276e+00, -2.8009e+00, -5.9103e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.0103e-01, -1.5619e+00, -1.4029e+00, -1.9788e+00],\n",
      "        [-2.4829e-02, -4.7536e+00, -4.1414e+00, -1.2943e+01],\n",
      "        [-1.5112e+00, -1.7896e+00, -1.1917e+00, -1.1757e+00],\n",
      "        ...,\n",
      "        [-8.8040e+00, -2.6181e+00, -1.2585e-01, -3.0976e+00],\n",
      "        [-9.8774e+00, -5.4623e+00, -4.6193e+00, -1.4256e-02],\n",
      "        [-1.0120e-04, -1.2796e+01, -9.2690e+00, -1.2378e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4385\n",
      "x tensor([[ 1.6761e-01, -5.9980e-01, -3.6052e-01, -8.6962e-01],\n",
      "        [ 3.7295e+00, -1.3862e+00, -4.8652e-01, -9.3521e+00],\n",
      "        [-3.0593e-01, -6.6766e-01, -1.3403e-03,  6.6684e-02],\n",
      "        ...,\n",
      "        [-6.1208e+00, -2.8422e-02,  2.5247e+00, -4.2338e-01],\n",
      "        [-5.7622e+00, -1.4771e+00, -5.0901e-01,  4.1836e+00],\n",
      "        [ 6.5627e+00, -6.5747e+00, -2.8031e+00, -5.8256e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.7894e-01, -1.6464e+00, -1.4071e+00, -1.9162e+00],\n",
      "        [-2.0548e-02, -5.1363e+00, -4.2366e+00, -1.3102e+01],\n",
      "        [-1.5050e+00, -1.8667e+00, -1.2004e+00, -1.1324e+00],\n",
      "        ...,\n",
      "        [-8.7682e+00, -2.6758e+00, -1.2261e-01, -3.0707e+00],\n",
      "        [-9.9584e+00, -5.6733e+00, -4.7052e+00, -1.2611e-02],\n",
      "        [-9.1787e-05, -1.3137e+01, -9.3658e+00, -1.2388e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4346\n",
      "x tensor([[ 0.1487, -0.3058, -0.4454, -1.1245],\n",
      "        [ 3.6076, -0.9562, -0.5414, -9.7095],\n",
      "        [-0.3225, -0.4398, -0.0630, -0.1233],\n",
      "        ...,\n",
      "        [-6.1619,  0.2286,  2.5055, -0.6612],\n",
      "        [-5.8691, -1.1152, -0.6409,  4.0038],\n",
      "        [ 6.4261, -5.9999, -2.9271, -6.0914]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.0293e-01, -1.3574e+00, -1.4970e+00, -2.1761e+00],\n",
      "        [-2.5866e-02, -4.5897e+00, -4.1749e+00, -1.3343e+01],\n",
      "        [-1.4830e+00, -1.6002e+00, -1.2235e+00, -1.2838e+00],\n",
      "        ...,\n",
      "        [-8.8027e+00, -2.4122e+00, -1.3534e-01, -3.3020e+00],\n",
      "        [-9.8883e+00, -5.1345e+00, -4.6601e+00, -1.5526e-02],\n",
      "        [-9.4409e-05, -1.2426e+01, -9.3533e+00, -1.2518e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4330\n",
      "x tensor([[ 0.2291, -0.7754, -0.3678, -0.7378],\n",
      "        [ 3.9327, -1.8630, -0.3817, -9.2758],\n",
      "        [-0.2732, -0.7932,  0.0107,  0.1369],\n",
      "        ...,\n",
      "        [-6.0779, -0.1222,  2.5562, -0.4269],\n",
      "        [-5.7820, -1.7035, -0.5053,  4.3828],\n",
      "        [ 6.7049, -6.9567, -2.8212, -5.5765]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.3159e-01, -1.8362e+00, -1.4285e+00, -1.7985e+00],\n",
      "        [-1.6284e-02, -5.8120e+00, -4.3307e+00, -1.3225e+01],\n",
      "        [-1.4884e+00, -2.0084e+00, -1.2045e+00, -1.0782e+00],\n",
      "        ...,\n",
      "        [-8.7470e+00, -2.7913e+00, -1.1287e-01, -3.0960e+00],\n",
      "        [-1.0175e+01, -6.0961e+00, -4.8979e+00, -9.7998e-03],\n",
      "        [-7.8794e-05, -1.3662e+01, -9.5261e+00, -1.2281e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4322\n",
      "x tensor([[ 9.6503e-02, -2.8483e-01, -3.9151e-01, -1.2362e+00],\n",
      "        [ 3.5498e+00, -1.1349e+00, -3.5662e-01, -9.8686e+00],\n",
      "        [-3.7445e-01, -4.1345e-01, -8.6361e-04, -2.3628e-01],\n",
      "        ...,\n",
      "        [-6.3330e+00,  3.3350e-01,  2.6578e+00, -8.5749e-01],\n",
      "        [-6.1901e+00, -1.0650e+00, -5.3933e-01,  3.9843e+00],\n",
      "        [ 6.2727e+00, -6.1230e+00, -2.7921e+00, -6.2898e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.4023e-01, -1.3216e+00, -1.4282e+00, -2.2729e+00],\n",
      "        [-2.8926e-02, -4.7137e+00, -3.9354e+00, -1.3447e+01],\n",
      "        [-1.5180e+00, -1.5569e+00, -1.1444e+00, -1.3798e+00],\n",
      "        ...,\n",
      "        [-9.1110e+00, -2.4445e+00, -1.2020e-01, -3.6355e+00],\n",
      "        [-1.0192e+01, -5.0665e+00, -4.5408e+00, -1.7154e-02],\n",
      "        [-1.2325e-04, -1.2396e+01, -9.0649e+00, -1.2563e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4261\n",
      "x tensor([[ 2.7913e-01, -6.6485e-01, -4.7232e-01, -8.1730e-01],\n",
      "        [ 3.9855e+00, -1.8284e+00, -4.0763e-01, -9.5216e+00],\n",
      "        [-2.3487e-01, -7.0874e-01, -7.3491e-02,  8.2702e-02],\n",
      "        ...,\n",
      "        [-6.1038e+00,  5.2409e-03,  2.5075e+00, -5.3177e-01],\n",
      "        [-5.8776e+00, -1.5655e+00, -6.3079e-01,  4.4066e+00],\n",
      "        [ 6.7659e+00, -7.0832e+00, -2.9596e+00, -5.7644e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-7.8610e-01, -1.7301e+00, -1.5376e+00, -1.8825e+00],\n",
      "        [-1.5233e-02, -5.8291e+00, -4.4083e+00, -1.3522e+01],\n",
      "        [-1.4283e+00, -1.9022e+00, -1.2669e+00, -1.1107e+00],\n",
      "        ...,\n",
      "        [-8.7335e+00, -2.6245e+00, -1.2217e-01, -3.1615e+00],\n",
      "        [-1.0293e+01, -5.9811e+00, -5.0464e+00, -9.0332e-03],\n",
      "        [-6.4252e-05, -1.3849e+01, -9.7255e+00, -1.2530e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4176\n",
      "x tensor([[  0.1116,  -0.4641,  -0.3630,  -1.0978],\n",
      "        [  3.6830,  -1.4962,  -0.2111, -10.0073],\n",
      "        [ -0.3657,  -0.5658,   0.0174,  -0.1047],\n",
      "        ...,\n",
      "        [ -6.3257,   0.2016,   2.6775,  -0.7772],\n",
      "        [ -6.2369,  -1.3312,  -0.5042,   4.2478],\n",
      "        [  6.3904,  -6.6667,  -2.7398,  -6.1149]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.0942e-01, -1.4851e+00, -1.3840e+00, -2.1188e+00],\n",
      "        [-2.5663e-02, -5.2048e+00, -3.9198e+00, -1.3716e+01],\n",
      "        [-1.5225e+00, -1.7226e+00, -1.1394e+00, -1.2615e+00],\n",
      "        ...,\n",
      "        [-9.1128e+00, -2.5855e+00, -1.0958e-01, -3.5643e+00],\n",
      "        [-1.0497e+01, -5.5913e+00, -4.7644e+00, -1.2362e-02],\n",
      "        [-1.1420e-04, -1.3057e+01, -9.1303e+00, -1.2505e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4084\n",
      "x tensor([[  0.1747,  -0.4721,  -0.4384,  -1.0592],\n",
      "        [  3.8709,  -1.6123,  -0.2681, -10.1156],\n",
      "        [ -0.3131,  -0.5786,  -0.0512,  -0.0607],\n",
      "        ...,\n",
      "        [ -6.2344,   0.1880,   2.5963,  -0.7630],\n",
      "        [ -6.1284,  -1.3655,  -0.6104,   4.3153],\n",
      "        [  6.5381,  -6.7273,  -2.8746,  -5.9983]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.5721e-01, -1.5040e+00, -1.4702e+00, -2.0911e+00],\n",
      "        [-1.9897e-02, -5.5030e+00, -4.1589e+00, -1.4006e+01],\n",
      "        [-1.4710e+00, -1.7364e+00, -1.2090e+00, -1.2185e+00],\n",
      "        ...,\n",
      "        [-8.9484e+00, -2.5260e+00, -1.1767e-01, -3.4770e+00],\n",
      "        [-1.0454e+01, -5.6915e+00, -4.9363e+00, -1.0641e-02],\n",
      "        [-8.7019e-05, -1.3265e+01, -9.4128e+00, -1.2536e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.4025\n",
      "x tensor([[  0.2305,  -0.6481,  -0.4436,  -0.9068],\n",
      "        [  4.0667,  -2.0113,  -0.2221, -10.0209],\n",
      "        [ -0.2742,  -0.7141,  -0.0532,   0.0498],\n",
      "        ...,\n",
      "        [ -6.1862,   0.0672,   2.5846,  -0.6786],\n",
      "        [ -6.0785,  -1.5906,  -0.6067,   4.4865],\n",
      "        [  6.6942,  -7.1542,  -2.8940,  -5.8119]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.0900e-01, -1.6876e+00, -1.4831e+00, -1.9463e+00],\n",
      "        [-1.5888e-02, -6.0939e+00, -4.3047e+00, -1.4103e+01],\n",
      "        [-1.4526e+00, -1.8925e+00, -1.2316e+00, -1.1286e+00],\n",
      "        ...,\n",
      "        [-8.8833e+00, -2.6299e+00, -1.1251e-01, -3.3757e+00],\n",
      "        [-1.0573e+01, -6.0855e+00, -5.1016e+00, -8.4234e-03],\n",
      "        [-7.3192e-05, -1.3848e+01, -9.5882e+00, -1.2506e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.3999\n",
      "x tensor([[  0.0731,  -0.3425,  -0.3722,  -1.2877],\n",
      "        [  3.6686,  -1.5202,  -0.0691, -10.4838],\n",
      "        [ -0.4039,  -0.4750,   0.0209,  -0.2415],\n",
      "        ...,\n",
      "        [ -6.4481,   0.3694,   2.7341,  -0.9983],\n",
      "        [ -6.5208,  -1.1925,  -0.5160,   4.2262],\n",
      "        [  6.2480,  -6.6041,  -2.7338,  -6.4023]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.3887e-01, -1.3545e+00, -1.3841e+00, -2.2996e+00],\n",
      "        [-2.8964e-02, -5.2178e+00, -3.7667e+00, -1.4181e+01],\n",
      "        [-1.5341e+00, -1.6052e+00, -1.1093e+00, -1.3717e+00],\n",
      "        ...,\n",
      "        [-9.2938e+00, -2.4763e+00, -1.1155e-01, -3.8440e+00],\n",
      "        [-1.0760e+01, -5.4318e+00, -4.7553e+00, -1.3088e-02],\n",
      "        [-1.3148e-04, -1.2852e+01, -8.9819e+00, -1.2650e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.3991\n",
      "x tensor([[ 0.3067, -0.7616, -0.4924, -0.7958],\n",
      "        [ 4.1992, -2.3310, -0.1616, -9.9745],\n",
      "        [-0.2312, -0.7841, -0.0703,  0.0946],\n",
      "        ...,\n",
      "        [-6.1610,  0.0355,  2.5879, -0.6961],\n",
      "        [-6.0972, -1.7290, -0.6656,  4.6802],\n",
      "        [ 6.8547, -7.5879, -2.9878, -5.7627]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-7.5397e-01, -1.8222e+00, -1.5530e+00, -1.8564e+00],\n",
      "        [-1.4128e-02, -6.5443e+00, -4.3749e+00, -1.4188e+01],\n",
      "        [-1.4195e+00, -1.9724e+00, -1.2586e+00, -1.0937e+00],\n",
      "        ...,\n",
      "        [-8.8583e+00, -2.6617e+00, -1.0933e-01, -3.3933e+00],\n",
      "        [-1.0784e+01, -6.4155e+00, -5.3522e+00, -6.4149e-03],\n",
      "        [-5.6980e-05, -1.4443e+01, -9.8425e+00, -1.2617e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.3972\n",
      "x tensor([[ 1.1091e-01, -3.2784e-01, -4.2463e-01, -1.3009e+00],\n",
      "        [ 3.7567e+00, -1.6438e+00, -1.6901e-02, -1.0655e+01],\n",
      "        [-3.8314e-01, -4.5089e-01, -6.4668e-03, -2.8198e-01],\n",
      "        ...,\n",
      "        [-6.4293e+00,  4.2691e-01,  2.7188e+00, -1.1031e+00],\n",
      "        [-6.5698e+00, -1.1710e+00, -5.6423e-01,  4.2465e+00],\n",
      "        [ 6.3248e+00, -6.6405e+00, -2.7992e+00, -6.4269e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-9.0580e-01, -1.3445e+00, -1.4413e+00, -2.3176e+00],\n",
      "        [-2.7113e-02, -5.4276e+00, -3.8007e+00, -1.4439e+01],\n",
      "        [-1.5037e+00, -1.5715e+00, -1.1270e+00, -1.4026e+00],\n",
      "        ...,\n",
      "        [-9.2642e+00, -2.4080e+00, -1.1606e-01, -3.9380e+00],\n",
      "        [-1.0829e+01, -5.4300e+00, -4.8233e+00, -1.2522e-02],\n",
      "        [-1.1420e-04, -1.2965e+01, -9.1241e+00, -1.2752e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.3896\n",
      "x tensor([[  0.1918,  -0.6858,  -0.3972,  -0.9705],\n",
      "        [  4.0692,  -2.3170,   0.0815, -10.4401],\n",
      "        [ -0.3229,  -0.7326,   0.0106,  -0.0236],\n",
      "        ...,\n",
      "        [ -6.3458,   0.1466,   2.7305,  -0.8732],\n",
      "        [ -6.3990,  -1.6615,  -0.5519,   4.6508],\n",
      "        [  6.6263,  -7.3925,  -2.7971,  -5.9392]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.2566e-01, -1.7033e+00, -1.4147e+00, -1.9880e+00],\n",
      "        [-2.0026e-02, -6.4062e+00, -4.0077e+00, -1.4529e+01],\n",
      "        [-1.4836e+00, -1.8933e+00, -1.1501e+00, -1.1842e+00],\n",
      "        ...,\n",
      "        [-9.1741e+00, -2.6817e+00, -9.7871e-02, -3.7015e+00],\n",
      "        [-1.1057e+01, -6.3196e+00, -5.2100e+00, -7.3049e-03],\n",
      "        [-8.5112e-05, -1.4019e+01, -9.4235e+00, -1.2566e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.3802\n",
      "x tensor([[  0.2341,  -0.4960,  -0.5465,  -1.0720],\n",
      "        [  4.1096,  -2.0585,  -0.0840, -10.7188],\n",
      "        [ -0.2771,  -0.5977,  -0.1320,  -0.0578],\n",
      "        ...,\n",
      "        [ -6.3345,   0.2863,   2.6009,  -0.9149],\n",
      "        [ -6.3654,  -1.4517,  -0.7649,   4.6249],\n",
      "        [  6.6351,  -7.1732,  -3.0457,  -6.0995]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-7.9336e-01, -1.5235e+00, -1.5740e+00, -2.0995e+00],\n",
      "        [-1.7041e-02, -6.1852e+00, -4.2106e+00, -1.4846e+01],\n",
      "        [-1.4175e+00, -1.7382e+00, -1.2725e+00, -1.1982e+00],\n",
      "        ...,\n",
      "        [-9.0565e+00, -2.4357e+00, -1.2103e-01, -3.6368e+00],\n",
      "        [-1.0997e+01, -6.0835e+00, -5.3967e+00, -6.8519e-03],\n",
      "        [-6.6397e-05, -1.3808e+01, -9.6809e+00, -1.2735e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.3744\n",
      "x tensor([[  0.1018,  -0.4809,  -0.3432,  -1.3178],\n",
      "        [  3.9360,  -2.0727,   0.2432, -11.1333],\n",
      "        [ -0.3841,  -0.5935,   0.0419,  -0.2370],\n",
      "        ...,\n",
      "        [ -6.4922,   0.3278,   2.7879,  -1.0860],\n",
      "        [ -6.6385,  -1.4627,  -0.4959,   4.4523],\n",
      "        [  6.4566,  -7.2756,  -2.6904,  -6.6079]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.9240e-01, -1.4751e+00, -1.3375e+00, -2.3120e+00],\n",
      "        [-2.6994e-02, -6.0356e+00, -3.7197e+00, -1.5096e+01],\n",
      "        [-1.5042e+00, -1.7136e+00, -1.0782e+00, -1.3572e+00],\n",
      "        ...,\n",
      "        [-9.3811e+00, -2.5611e+00, -1.0102e-01, -3.9749e+00],\n",
      "        [-1.1101e+01, -5.9248e+00, -4.9580e+00, -9.7619e-03],\n",
      "        [-1.0979e-04, -1.3732e+01, -9.1471e+00, -1.3065e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.3715\n",
      "x tensor([[  0.2357,  -0.6808,  -0.5382,  -0.8906],\n",
      "        [  4.1665,  -2.4352,   0.0408, -10.6822],\n",
      "        [ -0.2884,  -0.7292,  -0.1135,   0.0588],\n",
      "        ...,\n",
      "        [ -6.4248,   0.1907,   2.6383,  -0.8226],\n",
      "        [ -6.4996,  -1.6915,  -0.7205,   4.9154],\n",
      "        [  6.7147,  -7.7629,  -3.0609,  -5.9247]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-7.8180e-01, -1.6983e+00, -1.5556e+00, -1.9081e+00],\n",
      "        [-1.7359e-02, -6.6191e+00, -4.1430e+00, -1.4866e+01],\n",
      "        [-1.4469e+00, -1.8877e+00, -1.2719e+00, -1.0997e+00],\n",
      "        ...,\n",
      "        [-9.1746e+00, -2.5591e+00, -1.1156e-01, -3.5724e+00],\n",
      "        [-1.1420e+01, -6.6118e+00, -5.6408e+00, -4.9174e-03],\n",
      "        [-6.0556e-05, -1.4478e+01, -9.7757e+00, -1.2640e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.3696\n",
      "x tensor([[  0.1624,  -0.3395,  -0.4538,  -1.4582],\n",
      "        [  4.0741,  -2.0250,   0.2051, -11.4487],\n",
      "        [ -0.3507,  -0.4615,  -0.0228,  -0.3918],\n",
      "        ...,\n",
      "        [ -6.4180,   0.4850,   2.7235,  -1.2983],\n",
      "        [ -6.5784,  -1.2874,  -0.6035,   4.2616],\n",
      "        [  6.6010,  -7.0914,  -2.8403,  -6.8522]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.5147e-01, -1.3534e+00, -1.4677e+00, -2.4721e+00],\n",
      "        [-2.2861e-02, -6.1219e+00, -3.8919e+00, -1.5546e+01],\n",
      "        [-1.4453e+00, -1.5560e+00, -1.1173e+00, -1.4864e+00],\n",
      "        ...,\n",
      "        [-9.2590e+00, -2.3560e+00, -1.1747e-01, -4.1392e+00],\n",
      "        [-1.0852e+01, -5.5606e+00, -4.8766e+00, -1.1555e-02],\n",
      "        [-8.1893e-05, -1.3693e+01, -9.4414e+00, -1.3453e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.3670\n",
      "x tensor([[ 1.6313e-01, -7.6871e-01, -4.2930e-01, -9.1366e-01],\n",
      "        [ 4.1707e+00, -2.6775e+00,  2.7304e-01, -1.0935e+01],\n",
      "        [-3.6355e-01, -7.8314e-01,  7.4736e-03, -5.7661e-03],\n",
      "        ...,\n",
      "        [-6.5313e+00,  1.7876e-01,  2.7368e+00, -8.9407e-01],\n",
      "        [-6.6384e+00, -1.8533e+00, -5.6844e-01,  4.8822e+00],\n",
      "        [ 6.6344e+00, -7.8689e+00, -2.8715e+00, -5.9533e+00]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-8.2746e-01, -1.7593e+00, -1.4199e+00, -1.9043e+00],\n",
      "        [-2.1125e-02, -6.8693e+00, -3.9188e+00, -1.5127e+01],\n",
      "        [-1.5122e+00, -1.9318e+00, -1.1412e+00, -1.1544e+00],\n",
      "        ...,\n",
      "        [-9.3671e+00, -2.6570e+00, -9.8979e-02, -3.7299e+00],\n",
      "        [-1.1526e+01, -6.7410e+00, -5.4561e+00, -5.4762e-03],\n",
      "        [-7.8317e-05, -1.4503e+01, -9.5061e+00, -1.2588e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.3605\n",
      "x tensor([[  0.2115,  -0.4088,  -0.6048,  -1.2121],\n",
      "        [  4.1957,  -2.2023,   0.0790, -11.4067],\n",
      "        [ -0.3141,  -0.5135,  -0.1505,  -0.1972],\n",
      "        ...,\n",
      "        [ -6.4782,   0.4628,   2.6107,  -1.1280],\n",
      "        [ -6.5229,  -1.4290,  -0.8304,   4.5739],\n",
      "        [  6.6576,  -7.3192,  -3.1664,  -6.4273]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-7.9782e-01, -1.4182e+00, -1.6141e+00, -2.2214e+00],\n",
      "        [-1.7804e-02, -6.4158e+00, -4.1345e+00, -1.5620e+01],\n",
      "        [-1.4161e+00, -1.6155e+00, -1.2525e+00, -1.2992e+00],\n",
      "        ...,\n",
      "        [-9.2205e+00, -2.2795e+00, -1.3158e-01, -3.8703e+00],\n",
      "        [-1.1104e+01, -6.0099e+00, -5.4113e+00, -6.9594e-03],\n",
      "        [-5.6980e-05, -1.3977e+01, -9.8241e+00, -1.3085e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 0.3537\n",
      "x tensor([[  0.2363,  -0.6856,  -0.3585,  -1.3862],\n",
      "        [  4.2821,  -2.6026,   0.4384, -11.7286],\n",
      "        [ -0.4735,  -0.7370,   0.0754,  -0.2001],\n",
      "        ...,\n",
      "        [ -6.5131,   0.3048,   2.8133,  -1.1816],\n",
      "        [ -6.5274,  -1.8932,  -0.4785,   4.4340],\n",
      "        [  6.7714,  -7.9490,  -2.7499,  -6.7972]], grad_fn=<AddBackward0>)\n",
      "softmax tensor([[-7.6396e-01, -1.6859e+00, -1.3588e+00, -2.3865e+00],\n",
      "        [-2.2190e-02, -6.9070e+00, -3.8659e+00, -1.6033e+01],\n",
      "        [-1.5715e+00, -1.8351e+00, -1.0227e+00, -1.2981e+00],\n",
      "        ...,\n",
      "        [-9.4216e+00, -2.6037e+00, -9.5207e-02, -4.0901e+00],\n",
      "        [-1.0971e+01, -6.3363e+00, -4.9216e+00, -9.1168e-03],\n",
      "        [-7.4980e-05, -1.4720e+01, -9.5214e+00, -1.3569e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Accuracy: 0.8789\n"
     ]
    }
   ],
   "source": [
    "class GNNModel(MessagePassing):\n",
    "    def __init__(self, num_genes, hidden_dim, num_classes):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(num_genes, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        print(\"x\", x)\n",
    "        print(\"softmax\", F.log_softmax(x, dim=1))\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "# Extract the number of genes from the dataset\n",
    "num_genes = sampled_data.X.shape[1]\n",
    "hidden_dim = 256\n",
    "# Extract the number of cell types/classes from the dataset\n",
    "num_classes = len(np.unique(data.y))\n",
    "model = GNNModel(num_genes, hidden_dim, num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "transform = RandomLinkSplit(is_undirected=True, num_val=0.1, num_test=0.1)\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "# Print the sizes of the splits\n",
    "print(\"Train set size:\", train_data.num_edges)\n",
    "print(\"Validation set size:\", val_data.num_edges)\n",
    "print(\"Test set size:\", test_data.num_edges)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # print(\"training\")\n",
    "    optimizer.zero_grad()\n",
    "    out = model(train_data.x, train_data.edge_index)\n",
    "    # print(\"out\", out)\n",
    "    out = out.float().squeeze()\n",
    "    target = torch.from_numpy(train_data.y)\n",
    "    # since out is a cells by classes matrix and target is just a one dimensional matrix with the correct class for each cell,\n",
    "    # nll_loss would already be comparing the different probabilities of each class to find the loss\n",
    "    loss = F.nll_loss(out, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Loss: {loss:.4f}')\n",
    "    \n",
    "# Evaluation\n",
    "model.eval()\n",
    "pred = model(test_data.x, test_data.edge_index).argmax(dim=1)\n",
    "correct = (pred == torch.tensor(test_data.y)).sum()\n",
    "acc = int(correct) / int(test_data.x.shape[0])\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('gnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "780043200c56c5c84c374b9de1a911c52845a6ed6a319cff0276aba9b0882d2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
